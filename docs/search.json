[
  {
    "objectID": "index-listing.html",
    "href": "index-listing.html",
    "title": "All the things",
    "section": "",
    "text": "Use the sort, filter, and categories list to the right to find what you are looking for.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\n\n\n\nOther stuff\n\n\n\n\nLinks for Chapter 1\n\n\n\n\nLinks for Chapter 2\n\n\n\n\nFigure 2.4: Two point patterns in absolute space\n\n\n\n\nFigure 2.7: Voronoi polygons associated with a set of point locations\n\n\n\n\nFigure 2.8: Voronoi polygons associated with lines and polygons\n\n\n\n\nFigure 2.1: A representation of an absolute space\n\n\n\n\nFigure 2.9: A range of spatial weights applied to polygon data\n\n\n\n\nLinks for Chapter 3\n\n\n\n\nFigure 3.9: Equal area world in a square\n\n\n\n\nFigure 3.7: Two simple world projections\n\n\n\n\nFigure 3.8: A loxodrome on the sphere and projected\n\n\n\n\nLinks for Chapter 4\n\n\n\n\nFigure 4.5: Te Reo Māori toponyms in Aotearoa\n\n\n\n\nFigure 4.3: Many Springfields\n\n\n\n\nFigure 4.1: Geohashes and hierarchical indexing\n\n\n\n\nLinks for Chapter 5\n\n\n\n\nFigure 5.7: The MAUP aggregation effect\n\n\n\n\nFigure 5.1: The 9-intersection model of topological relations\n\n\n\n\nFigure 5.5: Maps of areas with widely varying populations\n\n\n\n\nFigure 5.6: Simple illustration of the modifiable areal unit problem\n\n\n\n\nLinks for Chapter 6\n\n\n\n\nFigures 6.5 and 6.6: Reduced world city network viewed various ways\n\n\n\n\nFigure 6.14: Relative time map of the Santa Barbara street network\n\n\n\n\nFigure 6.10: The small world rewiring process\n\n\n\n\nFigure 6.11: The small world rewiring process in two dimensions\n\n\n\n\nFigure 6.12: A simple graph drawn nine different ways\n\n\n\n\nLinks for Chapter 7\n\n\n\n\nLinks for Chapter 8\n\n\n\n\n\n\nNo matching items\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap4/fig4-05-te-reo-names.html",
    "href": "chapters/chap4/fig4-05-te-reo-names.html",
    "title": "Figure 4.5: Te Reo Māori toponyms in Aotearoa",
    "section": "",
    "text": "I made an alternative version of this map for some slides. It shows off the little-known multiplication by an affine transform matrix superpower that sf somewhat surprisingly admits (it felt like a cheat-code when I came across it here).\n\n\nCode\nlibrary(sf)\nlibrary(tmap)\nlibrary(dplyr)\n\nang &lt;- 40 * pi / 180\nrotation &lt;- matrix(c(cos(ang), -sin(ang), \n                     sin(ang),  cos(ang)), 2, 2, byrow = TRUE)\n\nnz &lt;- st_read(\"nz-2193.gpkg\") %&gt;%\n  st_cast(\"POLYGON\") %&gt;%\n  mutate(geom = geom * rotation)\n\ntoponyms &lt;- st_read(\"placenames.gpkg\") %&gt;%\n  mutate(maori = reo &gt; 0) %&gt;%\n  mutate(geom = geom * rotation) %&gt;%\nst_filter(nz)\n\ntm_shape(nz) + \n  tm_fill(col = \"#eee8d5\") + \n  tm_shape(toponyms %&gt;% arrange(id)) +\n  tm_dots(col = \"maori\", palette = c(\"slategrey\", \"red\"), size = 0.005, alpha = 0.2,\n          legend.show = FALSE) +\n  tm_layout(frame = FALSE, inner.margins = 0.05, bg.color = \"#002b36\")\n\n\n\n\n\nAs noted in the book, the materials for this figure draw on the amazing work of Chris McDowall and Tim Denee in their We Are Here atlas, the Toitū Te Whenua – Land Information New Zealand gazetteer of placenames, and on Te Hiku Media’s Ngā-kupu tools.\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap4/index.html",
    "href": "chapters/chap4/index.html",
    "title": "Chapter 4",
    "section": "",
    "text": "Place and space are in some senses the ‘terrible twins’ of geography. Unlike space, where geographical thought on the matter has been more or less settled for decades, place is a concept that continues to attract attention. Some of the more interesting developments in giscience grapple with this topic seeing potential for a platial giscience (see this conference series) often drawing on the kinds of fuzzy data that can be derived from geotagged social media.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinks for Chapter 4\n\n\n\nlinks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.1: Geohashes and hierarchical indexing\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.3: Many Springfields\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.5: Te Reo Māori toponyms in Aotearoa\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap4/fig4-03-springfields.html",
    "href": "chapters/chap4/fig4-03-springfields.html",
    "title": "Figure 4.3: Many Springfields",
    "section": "",
    "text": "Many of the data preparation steps for this figure were initially carried out in QGIS. Here they have been implemented in R only.\nTo understand why this version is different from the published figure, read on…\nCode\nlibrary(sf)\nlibrary(tmap)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(units)\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap4/fig4-03-springfields.html#get-data",
    "href": "chapters/chap4/fig4-03-springfields.html#get-data",
    "title": "Figure 4.3: Many Springfields",
    "section": "Get data",
    "text": "Get data\nThe ‘Springfields’ data set was obtained using the following code (shown here but not run) to query the Nominatim geocoder.\n\n\nCode\nlibrary(sf)\nlibrary(dplyr)\nlibrary(stringr)\n\nquery &lt;- \"https://nominatim.openstreetmap.org/search\"\nplace &lt;- \"Springfield\"\nexcluded_places &lt;- \"\"\n\nresult &lt;- NULL\ngot_new_results &lt;- TRUE\nn_results &lt;- 0\nmax_n &lt;- 1000\n\nwhile (n_results &lt; max_n & got_new_results) {\n  url &lt;- str_flatten(c(\n    str_glue(\"{query}?q={place}&\"),\n    \"polygon_geojson=1&limit=50&format=geojson&\",\n    str_glue(\"exclude_place_ids={excluded_places}\")\n  ))\n  download.file(url, \"result.geojson\", quiet = TRUE, method = \"auto\")\n  next_result &lt;- st_read(\"result.geojson\")\n  got_new_results &lt;- dim(next_result)[1] &gt; 0\n  if (is.null(result)) {\n    result &lt;- next_result\n  } else {\n    result &lt;- bind_rows(result, next_result)\n  }\n  n_results &lt;- dim(result)[1]\n  excluded_places &lt;- str_flatten(result$place_id, collapse = \",\")\n  Sys.sleep(1)\n}\n\nresult &lt; result %&gt;% \n  st_centroid() %&gt;% \n  st_write(str_glue(\"all-results-{place}.geojson\"))"
  },
  {
    "objectID": "chapters/chap4/fig4-03-springfields.html#make-a-map",
    "href": "chapters/chap4/fig4-03-springfields.html#make-a-map",
    "title": "Figure 4.3: Many Springfields",
    "section": "Make a map",
    "text": "Make a map\nOK, with that done, we can make a map. The degree of difficulty is much increased by choosing a Briesemeister projection. We choose projections like this one not because they are easy, but because they are hard (something like that…). Anyway the published map is actually an oblique Hammer-Aitoff projection, and not the right kind of oblique projection to be a Briesemeister…\nRecently, I unearthed a proj string at Michael Minn’s website, in the R code for this page that produces the Briesemeister projection. (However… I suspect that code is no longer entirely valid as the +M parameter included in that string no longer seems to have any effect on the output and the linked proj manual is v4.3, which is a long way out of date.)\nAnyway, here’s the string we are using—but even this is not the full story as we will see later.\n\n\nCode\nbries &lt;- \"+proj=ob_tran +o_proj=hammer +o_lon_p=0 +o_lat_p=45 +lon_0=10\"\n\n\n\nDealing with that weird projection\nA world ‘disc’ for the background. Make this by buffering a point and stretching it to an ellipse with the Hammer projection extent.\n\n\nCode\ndisc &lt;- st_point(c(0, 0)) %&gt;%\n  st_buffer(1, nQuadSegs = 90)\ndisc &lt;- disc * matrix(c(18040096, 0, 0, 9020048), 2, 2)\ndisc &lt;- disc %&gt;%\n  st_sfc() %&gt;%\n  st_sf(crs = bries)\n\n\nThe world countries must be cut at the Briesemeister ‘cut line’ which is where there is a break in the projection, to avoid anomalies when places are projected that cross the line. We figured out where this line is in other work…\n\n\nCode\ndata(\"World\")\n\ncut_line &lt;- st_read(\"briesemeister-cut-corrected.geojson\") %&gt;%\n  st_buffer(1000) # metres!\n\nworld &lt;- World %&gt;%\n  st_difference(cut_line) %&gt;%\n  st_transform(bries)\n\n\n\n\nMake a graticule\nA graticule - here we assemble this as linestrings (with many points) because projection of tm_graticules output can be problematic, especially if the projection has cuts other than at ±180° longitude (and even then it can have issues), or as in this case is in any way unusual.\n\n\nCode\nget_meridian &lt;- function(longitude) {\n  st_linestring(matrix(cbind(longitude, seq(-90, 90, 1)),\n                       ncol = 2, byrow = FALSE)) %&gt;%\n    st_sfc(crs = 4326)\n}\n\nget_meridians &lt;- function(spacing = 10) {\n  g &lt;- c()\n  for (lon in seq(-180, 180 - spacing, spacing)) {\n    g &lt;- c(g, get_meridian(longitude = lon))\n  }\n  g\n}\n\nget_parallel &lt;- function(latitude) {\n  st_linestring(matrix(cbind(seq(-180, 180, 1), latitude),\n                       ncol = 2, byrow = FALSE)) %&gt;%\n    st_sfc(crs = 4326)\n}\n\nget_parallels &lt;- function(spacing = 10) {\n  g &lt;- c()\n  for (lat in seq(-90 + spacing, 90 - spacing, spacing)) {\n    g &lt;- c(g, get_parallel(latitude = lat))\n  }\n  g\n}\n\ngraticule &lt;- c(get_meridians(), get_parallels()) %&gt;%\n  st_sfc(crs = 4326) %&gt;%\n  # again it must be cut at the Briesemeister breakline\n  st_difference(cut_line) %&gt;%\n  st_sfc() %&gt;%\n  st_sf() %&gt;%\n  st_transform(bries)\n\n\n\n\nAs it turns out\nAs noted, the published map is differently projected that the one we are making here. To get to the Briesemeister proper we have to stretch our oblique Hammer-Aitoff projection. See\n\nBriesemeister W. 1953. A new oblique equal-area projection. Geographical Review 43(2) 260–261. doi: 10.2307/211940.\n\nfor details. So let’s also do that here (this really is bonus material). We could use the +proj=affine transformation with appropriate settings, but I’ve had issues getting GDAL and tmap to cooperate with pipeline projected data. Instead, we’ll just use the weird matrix post-multiplication of geometries trick that sf allows to apply the required stretch. Unfortunately this does not update the CRS information, making these data layers useless for almost any other purpose.\n\n\nCode\nstretch_mat &lt;- matrix(c(sqrt(7/8), 0, 0, sqrt(8/7)), 2, 2)\ndisc &lt;- disc %&gt;%\n  mutate(geometry = geometry * stretch_mat)\nworld &lt;- world %&gt;%\n  mutate(geometry = geometry * stretch_mat)\ngraticule &lt;- graticule %&gt;%\n  mutate(geometry = geometry * stretch_mat)\n\n# and not forgetting the Springfields...\nspringfields &lt;- st_read(\"all-results-Springfield.geojson\") %&gt;%\n  st_transform(bries) %&gt;%\n  mutate(geometry = geometry * stretch_mat)\n\n\nFor what it’s worth, all these shenanigans are a good example of why more flexibility in the projection architectures of contemporary platforms would be welcome, something discussed in Chapter 3."
  },
  {
    "objectID": "chapters/chap4/fig4-03-springfields.html#yeah-ok-now-make-a-map-of-all-those-springfields",
    "href": "chapters/chap4/fig4-03-springfields.html#yeah-ok-now-make-a-map-of-all-those-springfields",
    "title": "Figure 4.3: Many Springfields",
    "section": "Yeah, OK, now make a map of all those Springfields",
    "text": "Yeah, OK, now make a map of all those Springfields\n\n\nCode\ntm_shape(disc) + \n  tm_fill(col = \"#eeeeee\") + \n  tm_shape(world) + \n  tm_fill(col = \"white\") +\n  tm_shape(springfields) +\n  tm_dots(col = \"red\", size = 0.15, alpha = 0.15) +\n  tm_shape(graticule) +\n  tm_lines(col = \"gray\", lwd = 0.5) +\n  tm_layout(frame = FALSE)\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "chapters/chap4/links-4.html",
    "href": "chapters/chap4/links-4.html",
    "title": "Links for Chapter 4",
    "section": "",
    "text": "The Bostonography neighborhoods web map is unfortunately no longer working (worth a try, but likely won’t work: bostonography.com/hoods). This blogpost explains the idea, which someone really should revive in other places, as did Hayden Rickard in his Masters thesis, cited in the text and viewable at this link.\n\n\n\nThe Nominatim geocoder is available at nominatim.openstreetmap.org.\n\n\n\nChris McDowall’s notes on the te reo Māori placenames map are at github.com/fogonwater/we-are-here. Te Hiku Media’s ngā-kupu tools for detecting Māori words in text at at github.com/TeHikuMedia/nga-kupu.\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap4/links-4.html#links",
    "href": "chapters/chap4/links-4.html#links",
    "title": "Links for Chapter 4",
    "section": "",
    "text": "The Bostonography neighborhoods web map is unfortunately no longer working (worth a try, but likely won’t work: bostonography.com/hoods). This blogpost explains the idea, which someone really should revive in other places, as did Hayden Rickard in his Masters thesis, cited in the text and viewable at this link.\n\n\n\nThe Nominatim geocoder is available at nominatim.openstreetmap.org.\n\n\n\nChris McDowall’s notes on the te reo Māori placenames map are at github.com/fogonwater/we-are-here. Te Hiku Media’s ngā-kupu tools for detecting Māori words in text at at github.com/TeHikuMedia/nga-kupu."
  },
  {
    "objectID": "chapters/chap4/fig4-01-hierarchical-indexing.html",
    "href": "chapters/chap4/fig4-01-hierarchical-indexing.html",
    "title": "Figure 4.1: Geohashes and hierarchical indexing",
    "section": "",
    "text": "I made this figure by hand in Inkscape, which was kind of fun, if a little tedious, given all the repetition involved. Here I show what I could have done instead in R.\nCode\nlibrary(dplyr)\nlibrary(tidyr)\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap4/fig4-01-hierarchical-indexing.html#the-z-order-morton-and-hilbert-curves",
    "href": "chapters/chap4/fig4-01-hierarchical-indexing.html#the-z-order-morton-and-hilbert-curves",
    "title": "Figure 4.1: Geohashes and hierarchical indexing",
    "section": "The Z-order (Morton) and Hilbert curves",
    "text": "The Z-order (Morton) and Hilbert curves\nThe first two are general indexing schemes with deep mathematical roots, so unsurprisingly there are R packages for working with them. The morton package is only available on github so you will need devtools to install it, while hilbert is on CRAN. Because I can, I’ve made these bigger than the labouriously hand-crafted examples in the book.\n\n\nCode\nlibrary(morton)\nlibrary(hilbert)\n\n# make a data frame to put the numbers in\ndf &lt;- tibble(n = 1:1023) %&gt;%\n  mutate(m1 = morton::fromMorton(n)[[1]],\n         m2 = -morton::fromMorton(n)[[2]])\n\n# the hilbert functions are hard to use with mutate, so \n# just use base R to make these\ndf$h1 &lt;- hilbert::position(df$n, n = 10)[, 1] + 33 # an offset\ndf$h2 &lt;- -hilbert::position(df$n, n = 10)[, 2]\n\n\nThat’s it—why didn’t I think of this earlier? And ggplot::geom_path() provides an easy way to plot the ‘curves’.\n\n\nCode\nlibrary(ggplot2)\n\nggplot(df) + \n  geom_path(aes(x = m1, y = m2), linewidth = 0.25) + \n  geom_path(aes(x = h1, y = h2), linewidth = 0.25) + \n  coord_equal() + \n  theme_void()"
  },
  {
    "objectID": "chapters/chap4/fig4-01-hierarchical-indexing.html#h3-hexagons",
    "href": "chapters/chap4/fig4-01-hierarchical-indexing.html#h3-hexagons",
    "title": "Figure 4.1: Geohashes and hierarchical indexing",
    "section": "H3 hexagons",
    "text": "H3 hexagons\nIf you like hexagons, you’ll love the h3forr package, which provides a spatial data friendly API for the H3 indexing scheme. There is an official H3 API for R but it focuses on the indexes and makes it harder work to fill spaces with hexagons, unlike the h3forr::polyfill() function.\nAnyway, here goes:\n\n\nCode\nlibrary(h3forr)\nlibrary(tmap)\nlibrary(sf)\nlibrary(maptiles)\n\n\nMake a 20km square near Wellington, Aotearoa.\n\n\nCode\nsquare &lt;- c(1.735e6 + 2e4 * c(0, 0, 1, 1, 0), \n            5.425e6 + 2e4 * c(0, 1, 1, 0, 0)) %&gt;%\n  matrix(ncol = 2) %&gt;%\n  list() %&gt;%\n  st_polygon() %&gt;%\n  st_sfc() %&gt;%\n  st_sf(crs = 2193) %&gt;%\n  st_transform(4326) # polyfill needs lat-lon\n\n\nA convenience function to wrap hsforr::polyfill() so that we retrieve all hexes within a buffered area of the supplied data.\n\n\nCode\nget_hexes &lt;- function(poly, resolution, distance) {\n  poly %&gt;% \n    st_buffer(distance) %&gt;%\n    polyfill(res = resolution) %&gt;% \n    h3_to_geo_boundary() %&gt;% \n    geo_boundary_to_sf()\n}\n\n\nThen get some hexagons.\n\n\nCode\nh3_4 &lt;- get_hexes(square, 4, 10000)\nh3_5 &lt;- get_hexes(square, 5, 5000)\nh3_6 &lt;- get_hexes(square, 6, 2500)\nh3_7 &lt;- get_hexes(square, 7, 1500)\nh3_8 &lt;- get_hexes(square, 8, 1000)\nh3_9 &lt;- get_hexes(square, 9, 750)\n\n\nAnd make a map. I’m using maptiles::get_tiles() to provide a base map.\n\n\nCode\nbasemap &lt;- get_tiles(square, zoom = 11, provider = \"CartoDB.Positron\")\n\ntm_shape(basemap, bbox = square) + tm_rgb() +\n  tm_shape(h3_4) + tm_borders(lwd = 5) +\n  tm_shape(h3_5) + tm_borders(lwd = 3) +\n  tm_shape(h3_6) + tm_borders(lwd = 2) +\n  tm_shape(h3_7) + tm_borders(lwd = 1) +\n  tm_shape(h3_8) + tm_borders(lwd = 0.5) +\n  tm_shape(h3_9) + tm_borders(lwd = 0.35) +\n  tm_credits(get_credit(\"CartoDB.Positron\"), bg.color = \"white\",\n             position = c(\"RIGHT\", \"BOTTOM\"), bg.alpha = 0.5)\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "chapters/chap3/fig3-09-tobler-chen.html",
    "href": "chapters/chap3/fig3-09-tobler-chen.html",
    "title": "Figure 3.9: Equal area world in a square",
    "section": "",
    "text": "This equal-area projection could replace Web Mercator as the top level global web tile ‘world in a square’.\nWith astonishing foresight, it was proposed for that purpose in this paper in 1986:\n\nTobler WR and ZT Chen. 1986. A quadtree for global information storage. Geographical Analysis 18(4) 360–371. doi: 10.1111/j.1538-4632.1986.tb00108.x.\n\nGiven the upset that accompanied the Gall-Peters projection, another ‘odd-looking’ equal-area projection (only ‘odd’ because people are so accustomed to Mercator), it’s not clear it would catch on! See this paper for a discussion of that controversy:\n\nCrampton, J. 1994. Cartography’s defining moment: the Peters projection controversy, 1974–1990. Cartographica 31(4) 16–32. doi: 10.3138/1821-6811-L372-345P.\n\nIn any case, this is simply a standard cylindrical equal-area projection with standard parallels chosen to make the whole map area square.\n\n\nCode\nlibrary(sf)\nlibrary(tmap)\nlibrary(tmaptools)\nlibrary(dplyr)\n\n\nUse the supplied World dataset (in lat-lon EPSG 4326) and project as required!\n\n\nCode\ndata(\"World\") \nworld_tc &lt;- World %&gt;%\n  select(geometry) %&gt;%\n  st_transform(\"+proj=cea lat_ts=55.654\")\n\ntm_shape(world_tc, bbox = bb(xlim = c(-180, 180),\n                             ylim = c(-90, 90))) +\n  tm_fill(col = \"#aaeecc\") +\n  tm_graticules(x = seq(-180, 180, 15), y = seq(-90, 90, 15),\n                labels.show = FALSE, lwd = 0.5) +\n  tm_layout(inner.margins = 0, bg.color = \"#ddeeff\")\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap3/index.html",
    "href": "chapters/chap3/index.html",
    "title": "Chapter 3",
    "section": "",
    "text": "Chapter 3 explores geographical thinking and giscience perspectives on scale. Thinking about cartographic scale inevitably demands consideration of map projections, which are also considered.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinks for Chapter 3\n\n\n\nlinks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.7: Two simple world projections\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.8: A loxodrome on the sphere and projected\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.9: Equal area world in a square\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap3/links-3.html",
    "href": "chapters/chap3/links-3.html",
    "title": "Links for Chapter 3",
    "section": "",
    "text": "The Degree Confluence Project is at confluence.org.\n\n\n\nFind out more about ‘Null Island’ (i.e., 0°N 0°E) at its wikipedia page.\n\n\n\nThe original announcement of geohash is in this blogpost by Greg Niemeyer: blog.labix.org/2008/02/26/geohashorg-is-public. You can generate geohash codes at the website http://geohash.org (yes http, not https).\n\n\n\nGoogle’s S2 index is explained at s2geometry.io.\n\n\n\nUber’s H3 index is described at h3geo.org.\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap3/links-3.html#links",
    "href": "chapters/chap3/links-3.html#links",
    "title": "Links for Chapter 3",
    "section": "",
    "text": "The Degree Confluence Project is at confluence.org.\n\n\n\nFind out more about ‘Null Island’ (i.e., 0°N 0°E) at its wikipedia page.\n\n\n\nThe original announcement of geohash is in this blogpost by Greg Niemeyer: blog.labix.org/2008/02/26/geohashorg-is-public. You can generate geohash codes at the website http://geohash.org (yes http, not https).\n\n\n\nGoogle’s S2 index is explained at s2geometry.io.\n\n\n\nUber’s H3 index is described at h3geo.org."
  },
  {
    "objectID": "chapters/chap3/fig3-10-raster-resolution.html",
    "href": "chapters/chap3/fig3-10-raster-resolution.html",
    "title": "Figure 3.10: Raster aggregation and disaggregation",
    "section": "",
    "text": "This figure shows how you can’t recover raster information after aggregation.\n\n\nCode\nlibrary(terra)\nlibrary(tmap)\nlibrary(dplyr)\n\n\nGet the data—you’ll need some of your own data here.\n\n\nCode\nz &lt;- rast(\"raster-data.tif\")\n\n\nAggregate and disaggregate by 10\n\n\nCode\nz10 &lt;- z %&gt;% \n  aggregate(10)\n\nz_dash &lt;- z10 %&gt;%\n  resample(z)\n\n\nDissolve to polygons, so we can make smaller image files and control the colouring. This step is slow.\n\n\nCode\nz_p &lt;- z %&gt;%\n  as.polygons(dissolve = FALSE) %&gt;%\n  as(\"Spatial\")\n\nz10_p &lt;- z10 %&gt;%\n  as.polygons(dissolve = FALSE) %&gt;%\n  as(\"Spatial\")\n\nz_dash_p &lt;- z_dash %&gt;%\n  as.polygons(dissolve = FALSE) %&gt;%\n  as(\"Spatial\")\n\n\nMake maps\n\n\nCode\nm1 &lt;- tm_shape(z_p) + \n  tm_fill(col = \"Band 1\", breaks = seq(180, 280, 10), \n          palette = \"BrBG\", style = \"fixed\") + \n  tm_legend(show = FALSE) + \n  tm_layout(inner.margins = 0, frame = FALSE)\n\nm2 &lt;- tm_shape(z10_p) + \n  tm_fill(col = \"Band 1\", breaks = seq(180, 280, 10), \n          palette = \"BrBG\", style = \"fixed\") + \n  tm_legend(show = FALSE) + \n  tm_layout(inner.margins = 0, frame = FALSE)\n\nm3 &lt;- tm_shape(z_dash_p) + \n  tm_fill(col = \"Band 1\", breaks = seq(180, 280, 10), \n          palette = \"BrBG\", style = \"fixed\") + \n  tm_legend(show = FALSE) + \n  tm_layout(inner.margins = 0, frame = FALSE)\n\ntmap_arrange(m1, m2, m3)\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap3/fig3-07-platte-carre-and-lcea.html",
    "href": "chapters/chap3/fig3-07-platte-carre-and-lcea.html",
    "title": "Figure 3.7: Two simple world projections",
    "section": "",
    "text": "Code\nlibrary(sf)\nlibrary(tmap)\nlibrary(tmaptools)\nlibrary(dplyr)\n\n\nUse the supplied World dataset (in lat-lon EPSG 4326) and make projections as required.\n\n\nCode\ndata(\"World\") \nworld &lt;- World %&gt;%\n  select(geometry)\n\n# Equal area with standard parallel at 0\nworld_lcea &lt;- world %&gt;%\n  st_transform(\"+proj=cea\")\n\n\nThat’s pretty much it. So here are the maps.\n\n\nCode\ntm_shape(world, bbox = bb(xlim = c(-180, 180),\n                          ylim = c(-90, 90))) +\n  tm_fill(col = \"#aaeecc\") +\n  tm_graticules(x = seq(-180, 180, 15), y = seq(-90, 90, 15),\n                labels.show = FALSE, lwd = 0.5) +\n  tm_layout(inner.margins = 0, bg.color = \"#ddeeff\")\n\n\n\n\n\nCode\ntm_shape(world_lcea, bbox = bb(xlim = c(-180, 180),\n                               ylim = c(-90, 90))) +\n  tm_fill(col = \"#aaeecc\") +\n  tm_graticules(x = seq(-180, 180, 15), y = seq(-90, 90, 15),\n                labels.show = FALSE, lwd = 0.5) +\n  tm_layout(inner.margins = 0, bg.color = \"#ddeeff\")\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap3/fig3-08-loxodrome.html",
    "href": "chapters/chap3/fig3-08-loxodrome.html",
    "title": "Figure 3.8: A loxodrome on the sphere and projected",
    "section": "",
    "text": "The figure produced below extends to ±89° which makes the point even more clearly, but doesn’t give a nice square Mercator projected map. See also Jason Davies’ page about loxodromes for more on this, including a couple of figures that probably on some level inspired mine. Indeed, Jason Davies’ pages include some gems for exploring the variety of global projections. See, for example, Map Projection Transitions.\nCode\nlibrary(dplyr)\nlibrary(sf)\nlibrary(tmap)\nlibrary(smoothr) # this is for interpolating along lines\nThis process is pretty complicated to do in R, so we need a bunch of helper functions. First, it is the default for sf now, but just to make the point, we intially use S2 mode, so that when we clip data with a hemisphere it does it properly.\nCode\nsf_use_s2(TRUE)\nAlso, define an orthographic projection for the globe view.\nCode\northo_proj &lt;- \"+proj=ortho lon_0=0 lat_0=40\"\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap3/fig3-08-loxodrome.html#make-a-hemisphere",
    "href": "chapters/chap3/fig3-08-loxodrome.html#make-a-hemisphere",
    "title": "Figure 3.8: A loxodrome on the sphere and projected",
    "section": "Make a hemisphere",
    "text": "Make a hemisphere\nMake a hemisphere for the globe view, and apply it to the built-in World dataset that ships with tmap.\n\n\nCode\nhemisphere &lt;- st_point(c(0, 0)) %&gt;%\n  st_buffer(6356752) %&gt;%\n  st_sfc(crs = ortho_proj) %&gt;%\n  densify() %&gt;%\n  st_transform(4326)\n\ndata(\"World\")\nworld_o &lt;- World %&gt;%\n  st_intersection(hemisphere) %&gt;%\n  st_transform(ortho_proj) %&gt;%\n  filter(st_is_empty(geometry) == FALSE)"
  },
  {
    "objectID": "chapters/chap3/fig3-08-loxodrome.html#helper-functions-for-coordinate-transformations",
    "href": "chapters/chap3/fig3-08-loxodrome.html#helper-functions-for-coordinate-transformations",
    "title": "Figure 3.8: A loxodrome on the sphere and projected",
    "section": "Helper functions for coordinate transformations",
    "text": "Helper functions for coordinate transformations\nNext, convenience ‘helper’ functions for converting coordinate pairs between projections, and converting degrees to radians. By default it will convert longitude-latitude to Mercator.\n\n\nCode\nx1y1_to_x2y2 &lt;- function(coords, crs1 = 4326, crs2 = \"+proj=merc\") {\n  coords %&gt;% st_point() %&gt;%\n    st_sfc(crs = crs1) %&gt;%\n    st_transform(crs2) %&gt;%\n    st_coordinates() %&gt;%\n    c()\n}\n\nget_radians &lt;- function(d) {\n  d * pi / 180\n}"
  },
  {
    "objectID": "chapters/chap3/fig3-08-loxodrome.html#making-a-loxodrome",
    "href": "chapters/chap3/fig3-08-loxodrome.html#making-a-loxodrome",
    "title": "Figure 3.8: A loxodrome on the sphere and projected",
    "section": "Making a loxodrome",
    "text": "Making a loxodrome\nThe next function makes a loxodrome line of equal bearing, starting from 89°S 180°E, and ending when it hits latitude 89°N (latitude range is determined by the lat parameter). The calculations are done in Mercator coordinates, since it is in this projection that a loxodrome is a straight line.\n\n\nCode\nget_loxodrome &lt;- function(lat = -89, bearing = 85, n = 100) {\n  transects &lt;- c() # empty vector for the west to east transects\n  pt &lt;- c(-180, lat)\n\n  # we keep going until we hit the latitude at lat North\n  while(TRUE && pt[2] &lt; -lat) {\n    p1 &lt;- x1y1_to_x2y2(pt) # convert to Mercator\n    # get the point at +180, ie 2 * pi radians in Mercator\n    p2 &lt;- c(-p1[1],         \n            p1[2] + tan(get_radians(90 - bearing)) * -2 * p1[1])\n    # the line is a densified version of this\n    transect &lt;- st_linestring(matrix(c(p1, p2), 2, 2, byrow = TRUE)) %&gt;%\n      st_sfc(crs = \"+proj=merc\") %&gt;%\n      densify(n) # the densification step (provided by smoothr)\n    transects &lt;- c(transects, transect)\n    # reset p1 to 'the other side' of the Mercator space i.e. -180\n    p1 &lt;- p2\n    pt &lt;- x1y1_to_x2y2(p1, crs1 = \"+proj=merc\", crs2 = 4326)\n    pt[1] &lt;- -180\n  }\n  # transects need tidying so they extend equally far N and S of equator\n  # max y coordinate should be the inverse of the minimum y coordinate\n  ymax &lt;- x1y1_to_x2y2(c(0, -lat))[2]\n  # apply this limit to the points along the last transect from west to east\n  n_transects &lt;- length(lines)\n  # convert the last transect to a set of points, to apply this limit\n  pts &lt;- transects[[n_transects]] %&gt;%\n    st_cast(\"MULTIPOINT\") %&gt;%\n    st_coordinates()\n  pts &lt;- pts[pts[, 2] &lt;= ymax, 1:2]\n  # and then convert back to a linestring\n  transects[[n_transects]] &lt;- pts %&gt;%\n    matrix(ncol = 2) %&gt;%\n    st_linestring()\n  # finally convert to lon-lat i.e. EPSG 4326\n  transects %&gt;% st_sfc(crs = \"+proj=merc\") %&gt;%\n    st_as_sf() %&gt;%\n    st_transform(4326)\n}"
  },
  {
    "objectID": "chapters/chap3/fig3-08-loxodrome.html#now-make-the-figure",
    "href": "chapters/chap3/fig3-08-loxodrome.html#now-make-the-figure",
    "title": "Figure 3.8: A loxodrome on the sphere and projected",
    "section": "Now make the figure!",
    "text": "Now make the figure!\n\nAssemble the layers\nMake a loxodrome and clip the world to the chosen latitude limits. To apply rectangular projection based limits we have to switch to planar geometry in sf. We have to do this because we can’t show the whole world in Mercator…\n\n\nCode\nlox &lt;- get_loxodrome() \nlox_o &lt;- lox %&gt;%\n  st_intersection(hemisphere)\n\nsf_use_s2(FALSE)\n\nmercator_limits &lt;- st_polygon(list(\n  matrix(c(-180, -89, 180, -89, 180, 89, -180, 89, -180, -89),\n  ncol = 2, byrow = TRUE))) %&gt;%\n  st_sfc(crs = 4326) %&gt;%\n  st_as_sf()\n\nworld_m &lt;- World %&gt;% \n  st_intersection(mercator_limits) %&gt;%\n  st_transform(\"+proj=merc\") %&gt;%\n  filter(st_is_empty(geometry) == FALSE)\n\nlox_m &lt;- lox %&gt;%\n  st_intersection(mercator_limits)\n\n\n\n\nPut them together\nAnd finally make the maps. (In the version in the book I handmade the graticule, not realising that there was a tm_graticules function in tmap…).\n\n\nCode\nm1 &lt;- tm_shape(world_o) + \n  tm_fill(col = \"lightgray\") +\n  tm_graticules(x = seq(-180, 165, 15), y = seq(-75, 75, 15), \n                col = \"gray\", lwd = 0.5, labels.show = FALSE) +\n  tm_shape(lox_o) + \n  tm_lines(col = \"black\") +\n  tm_layout(frame = FALSE)\n\nm2 &lt;- tm_shape(world_m, bbox = mercator_limits) + \n  tm_fill(col = \"lightgray\") +\n  tm_graticules(x = seq(-180, 165, 15), y = seq(-75, 75, 15), \n                col = \"gray\", lwd = 0.5, labels.show = FALSE) +\n  tm_shape(lox_m) + \n  tm_lines(col = \"black\") +\n  tm_layout(frame = FALSE)\n\ntmap_arrange(m1, m2, ncol = 2)\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "chapters/chap2/fig2-04-ppa-relative-space.html",
    "href": "chapters/chap2/fig2-04-ppa-relative-space.html",
    "title": "Figure 2.4: Two point patterns in absolute space",
    "section": "",
    "text": "Although it is labelled ‘point patterns in absolute space’, the real (ahem) point of this figure is that spatial analysis often works, in effect, with a relative concept of space, since it is based on notions as here, such as the distances between points.\nIf you want point patterns, you need the fantastic spatstat by Adrian Baddeley, Ege Rubak, and Rolf Turner.\n\n\nCode\nlibrary(spatstat)\n\n\nMake a couple of point patterns, one evenly-space using sequential spatial inhibition, and one clustered using a Thomas process. For the latter, see\n\nThomas M. 1949. A generalisation of Poisson’s binomial limit for use in ecology. Biometrika 36, 18–25.\n\n\n\nCode\npp1 &lt;- rSSI(0.07, n = 105)\npp2 &lt;- rThomas(10, 0.03, 10)\n\n\nCalculate nearest neighbour distances.\n\n\nCode\nnn1 &lt;- nndist(pp1)\nnn2 &lt;- nndist(pp2)\nbreaks &lt;- seq(0, round(max(c(nn1, nn2)), 1), length.out = 10)\n\n\nAnd plot them.\n\n\nCode\npar(mfrow = c(2, 2), mai = rep(0.3, 4))\n\nplot(pp1, main = \"\")\nhist(nn1, main = \"\", xlab = \"Distance\", ylab = \"Frequency\", breaks = breaks)\nplot(pp2, main = \"\")\nhist(nn2, main = \"\", xlab = \"Distance\", ylab = \"Frequency\", breaks = breaks)\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap2/fig2-07-point-voronoi.html",
    "href": "chapters/chap2/fig2-07-point-voronoi.html",
    "title": "Figure 2.7: Voronoi polygons associated with a set of point locations",
    "section": "",
    "text": "This is most conveniently made using spatstat, but I’ve shown it here making a point pattern into an sf dataset and then using sf::st_voronoi().\n\n\nCode\nlibrary(spatstat)\nlibrary(sf)\nlibrary(tmap)\n\n\nThere are a few steps making a spatstat point pattern into a simple features dataset…\n\n\nCode\npp &lt;- rpoispp(100) %&gt;%\n  as.data.frame() %&gt;%\n  st_as_sf(coords = c(\"x\", \"y\"), crs = 2193)\n\n\nAnd there are a few more making a point dataset into a Voronoi polygon dataset.\n\n\nCode\npp_vor &lt;- pp %&gt;%\n  st_union() %&gt;%\n  st_voronoi() %&gt;%\n  st_cast() %&gt;%\n  st_as_sf(crs = st_crs(pp))\n\n\nAnd finally a map.\n\n\nCode\ntm_shape(pp_vor, bbox = pp %&gt;% st_union() %&gt;% st_buffer(0.05)) + \n  tm_polygons(border.col = \"white\") +\n  tm_shape(pp) + \n  tm_bubbles(col = \"white\", alpha = 0, border.col = \"black\", size = 0.1) +\n  tm_layout(frame = FALSE)\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap2/index.html",
    "href": "chapters/chap2/index.html",
    "title": "Chapter 2",
    "section": "",
    "text": "The book proper starts with a look at what many consider geography’s key distinctive focus, namely space. This is often, in more GIS-adjacent settings understood as location, which led me directly to Whitehead’s arresting dismissal of simple location as an idea, something to which we return in Chapter 8. This chapter considers geographical theories about space and how space is—and potentially could be—represented in giscience. Many of the figures relate to some of the more interesting ways in which giscience represents space.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinks for Chapter 2\n\n\n\nlinks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.1: A representation of an absolute space\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.4: Two point patterns in absolute space\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.7: Voronoi polygons associated with a set of point locations\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.8: Voronoi polygons associated with lines and polygons\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.9: A range of spatial weights applied to polygon data\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap2/fig2-08-non-point-voronoi.html",
    "href": "chapters/chap2/fig2-08-non-point-voronoi.html",
    "title": "Figure 2.8: Voronoi polygons associated with lines and polygons",
    "section": "",
    "text": "This figure was mostly prepared in QGIS, but an R version is provided here to show the steps involved.\nDifferences between the versions are due to the original being prepared across a wider extent which was then clipped down to the final extent. The input data used here are already clipped to the final extent meaning there may be anomalies near the edges.\nCode\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tmap)\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap2/fig2-08-non-point-voronoi.html#load-data",
    "href": "chapters/chap2/fig2-08-non-point-voronoi.html#load-data",
    "title": "Figure 2.8: Voronoi polygons associated with lines and polygons",
    "section": "Load data",
    "text": "Load data\nYou’ll need your own roads and buildings data. Mine came from OpenStreetMap via the QGIS QuickOSM plugin.\n\n\nCode\nroads &lt;- st_read(\"final-roads.gpkg\") %&gt;%\n  select(full_id, osm_id)\nbldgs &lt;- st_read(\"final-buildings.gpkg\") %&gt;%\n  select(full_id, osm_id)\n\n\nAnd a quick map to see what we’re working with.\n\n\nCode\ntm_shape(bldgs) + \n  tm_fill() + \n  tm_shape(roads) + \n  tm_lines()"
  },
  {
    "objectID": "chapters/chap2/fig2-08-non-point-voronoi.html#interpolate-points-along-the-lines-and-polygon-boundaries",
    "href": "chapters/chap2/fig2-08-non-point-voronoi.html#interpolate-points-along-the-lines-and-polygon-boundaries",
    "title": "Figure 2.8: Voronoi polygons associated with lines and polygons",
    "section": "Interpolate points along the lines and polygon boundaries",
    "text": "Interpolate points along the lines and polygon boundaries\nPlace points along the boundaries of each of these.\nFor the roads we combine all elements into a single line object and assign the same id to every point generated.\n\n\nCode\nr_pts &lt;- roads %&gt;%\n  st_union() %&gt;%\n  st_cast(\"LINESTRING\") %&gt;%\n  st_line_sample(density = 1) %&gt;%\n  st_cast(\"POINT\") %&gt;%\n  st_as_sf() %&gt;%\n  rename(geometry = x) %&gt;% # geom column gets misnamed 'x' \n  mutate(id = \"0\")\n\n\nFor the buildings we wish to retain the building IDs, so we do a join based on the nearest feature in the buildings dataset.\n\n\nCode\nb_pts &lt;- bldgs %&gt;%\n  st_cast(\"MULTILINESTRING\") %&gt;%\n  st_cast(\"LINESTRING\") %&gt;%\n  # if any perimeter is &lt; 1 then the sampling step fails\n  filter(st_length(.) &gt;= units::as_units(1, \"m\")) %&gt;%\n  st_line_sample(density = 1) %&gt;%\n  st_cast(\"POINT\") %&gt;%\n  st_as_sf() %&gt;%\n  rename(geom = x) %&gt;%\n  st_join(bldgs, join = st_nearest_feature) %&gt;%\n  mutate(id = full_id) %&gt;%\n  select(id)"
  },
  {
    "objectID": "chapters/chap2/fig2-08-non-point-voronoi.html#make-the-point-voronoi-polygons",
    "href": "chapters/chap2/fig2-08-non-point-voronoi.html#make-the-point-voronoi-polygons",
    "title": "Figure 2.8: Voronoi polygons associated with lines and polygons",
    "section": "Make the point Voronoi polygons",
    "text": "Make the point Voronoi polygons\nNow combine the two into a single point dataset.\n\n\nCode\nall_pts &lt;- bind_rows(r_pts, b_pts)\n\n\nNow make a Voronoi layer from the points.\n\n\nCode\npts_vor &lt;- all_pts %&gt;%\n  st_union() %&gt;%\n  st_voronoi()%&gt;%\n  st_cast() %&gt;%\n  st_as_sf() %&gt;%\n  st_join(all_pts, left = FALSE) \n\n\nWe need to clip this to the extent of the buildings data.\n\n\nCode\nextent &lt;- bldgs %&gt;%\n  st_bbox() %&gt;%\n  st_as_sfc() %&gt;%\n  st_sf()\n\npts_vor &lt;- pts_vor %&gt;%\n  st_intersection(extent)\n\nplot(pts_vor, main = \"Voronoi of all points\", key.pos = NULL)"
  },
  {
    "objectID": "chapters/chap2/fig2-08-non-point-voronoi.html#finally-form-the-line-and-polygon-voronois",
    "href": "chapters/chap2/fig2-08-non-point-voronoi.html#finally-form-the-line-and-polygon-voronois",
    "title": "Figure 2.8: Voronoi polygons associated with lines and polygons",
    "section": "Finally form the line and polygon Voronois",
    "text": "Finally form the line and polygon Voronois\nNow we dissolve (group_by) on the id attribute.\n\n\nCode\ndiss_vor &lt;- pts_vor %&gt;%\n  group_by(id) %&gt;%\n  summarise()\n\nplot(diss_vor, main = \"Dissolved Voronois\", key.pos = NULL)"
  },
  {
    "objectID": "chapters/chap2/fig2-08-non-point-voronoi.html#make-a-map",
    "href": "chapters/chap2/fig2-08-non-point-voronoi.html#make-a-map",
    "title": "Figure 2.8: Voronoi polygons associated with lines and polygons",
    "section": "Make a map",
    "text": "Make a map\nFinally, we can make a map, similar to the one in Figure 2.8 in the book.\n\n\nCode\ntm_shape(bldgs, bbox = extent) +\n  tm_fill() + \n  # make the road into a polygon for clipping to extent\n  tm_shape(roads %&gt;% st_buffer(2) %&gt;% st_intersection(extent)) + \n  tm_fill(col = \"#cc9999\") +\n  # filter points so only those inside the extent are in the map\n  tm_shape(all_pts %&gt;% st_filter(extent %&gt;% st_buffer(-.1))) + \n  tm_dots(col = \"black\") +\n  tm_shape(pts_vor) + \n  tm_borders(col = \"lightgray\", lwd = 0.75) + \n  tm_shape(diss_vor) + \n  tm_borders(col = \"black\")\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "chapters/chap2/links-2.html",
    "href": "chapters/chap2/links-2.html",
    "title": "Links for Chapter 2",
    "section": "",
    "text": "As marketing copy, this one is always already out of date. As of September 2023, the most direct reference to location on the Esri website is to be found here: esri.com/en-us/arcgis/products/spatial-analytics-data-science/overview.\n\n\n\nScapeToad is still at http://scapetoad.choros.place/ (yes http, not https).\n\n\n\nThe TopoJSON format specification is at github.com/topojson/topojson-specification.\n\n\n\nThe GeoJSON format specification is at datatracker.ietf.org/doc/html/rfc7946\n\n\n\nYou can experiment with the GeoJSON format at geojson.io.\n\n\n\nDavid Theobald’s bewildered comment about the rendering speed of shapefiles is in an article in ArcUser entitled ‘Understanding topology and shapefiles’: esri.com/news/arcuser/0401/topo.html.\n\n\n\nThe PostGIS project home page: osgeo.org/projects/postgis/\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap2/links-2.html#links",
    "href": "chapters/chap2/links-2.html#links",
    "title": "Links for Chapter 2",
    "section": "",
    "text": "As marketing copy, this one is always already out of date. As of September 2023, the most direct reference to location on the Esri website is to be found here: esri.com/en-us/arcgis/products/spatial-analytics-data-science/overview.\n\n\n\nScapeToad is still at http://scapetoad.choros.place/ (yes http, not https).\n\n\n\nThe TopoJSON format specification is at github.com/topojson/topojson-specification.\n\n\n\nThe GeoJSON format specification is at datatracker.ietf.org/doc/html/rfc7946\n\n\n\nYou can experiment with the GeoJSON format at geojson.io.\n\n\n\nDavid Theobald’s bewildered comment about the rendering speed of shapefiles is in an article in ArcUser entitled ‘Understanding topology and shapefiles’: esri.com/news/arcuser/0401/topo.html.\n\n\n\nThe PostGIS project home page: osgeo.org/projects/postgis/"
  },
  {
    "objectID": "chapters/chap2/fig2-01-absolute-space.html",
    "href": "chapters/chap2/fig2-01-absolute-space.html",
    "title": "Figure 2.1: A representation of an absolute space",
    "section": "",
    "text": "A simple visualisation of geo-atoms in absolute space\n\n\nCode\nlibrary(plot3D)\nlibrary(dplyr)\n\n\nThere isn’t a lot to this. Just make a bunch of random numbers…\n\n\nCode\ndata &lt;- data.frame(x = rnorm(30), y = rnorm(30), z = rnorm(30))\n\n\n… and plot them.\n\n\nCode\nscatter3D(x = data$x, y = data$y, z = data$z, \n          theta = 25, phi = 30, scale = FALSE, \n          xlim = range(data$x) * 1.1, \n          ylim = range(data$y) * 1.1, \n          zlim = range(data$z) * 1.1, \n          pch = 19, col = \"#999999\", bty = \"u\", type = \"h\", \n          asp = 1, col.axis = \"#333333\", col.panel = \"#eeeeee\", \n          col.grid = \"#666666\", lwd.grid = 0.2, nticks = 6)\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap2/fig2-09-spatial-weights.html",
    "href": "chapters/chap2/fig2-09-spatial-weights.html",
    "title": "Figure 2.9: A range of spatial weights applied to polygon data",
    "section": "",
    "text": "This figure is intended to demonstrate the diversity of possible conceptualisations of ‘neighbour’ that are often deployed in spatial analysis contexts, and represent possible different approaches to relative space.\nThe spdep package I am using here is not the easiest to use. The best guidance on spdep I’ve found is in\nThe newer sfdep package is still finding its feet at time of writing (Oct 2023), but will likely be a better choice before long.\nCode\nlibrary(sf)\nlibrary(dplyr)\nlibrary(spdep)\nlibrary(sp)\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap2/fig2-09-spatial-weights.html#assembling-the-data",
    "href": "chapters/chap2/fig2-09-spatial-weights.html#assembling-the-data",
    "title": "Figure 2.9: A range of spatial weights applied to polygon data",
    "section": "Assembling the data",
    "text": "Assembling the data\nFirst read a polygons dataset. You’ll need to supply your own for this.\n\n\nCode\nchch &lt;- st_read(\"chch-sa2.gpkg\") # you need a spatial dataset\n\n\nspdep requires the data to be in the sp package format, so we convert to that.\n\n\nCode\npolys &lt;- chch %&gt;%\n  select(geom) %&gt;%\n  as(\"Spatial\")\n\n\nNow make some points inside the polygons, and also some centroids.\n\n\nCode\n# guaranteed inside the polygons\npts &lt;- chch %&gt;%\n  st_point_on_surface() %&gt;% \n  st_geometry()\n\n# not guaranteed, but better(?) for distance measurements\npts_c &lt;- chch %&gt;%\n  st_centroid() %&gt;% \n  st_geometry()"
  },
  {
    "objectID": "chapters/chap2/fig2-09-spatial-weights.html#maps-of-adjacencies-based-on-different-rules",
    "href": "chapters/chap2/fig2-09-spatial-weights.html#maps-of-adjacencies-based-on-different-rules",
    "title": "Figure 2.9: A range of spatial weights applied to polygon data",
    "section": "Maps of adjacencies based on different rules",
    "text": "Maps of adjacencies based on different rules\nThese are presented in a single figure in the book in four rows of three. Here I show them as sets of three for greater clarity.\n\nContiguity based\n\n\nCode\nlayout(matrix(1:3, ncol = 3, byrow = TRUE))\npar(mai = c(0, 0, 0.15, 0))\n\nnb &lt;- polys %&gt;% poly2nb(queen = TRUE)\nplot(polys, col = \"lightgrey\", lwd = 0.5, border = 'white', \n     main = \"Queen's rule adjacency\")\nplot(nb, pts, col = 'red', lwd = 0.5, add = TRUE)\n\nnb &lt;- polys %&gt;% poly2nb(queen = FALSE)\nplot(polys, col = \"lightgrey\", lwd = 0.5, border = 'white', \n     main = \"Rook's rule adjacency\")\nplot(nb, pts, col = 'red', lwd = 0.5, add = TRUE)\n\nnb &lt;- nb %&gt;% nblag(2) %&gt;% nblag_cumul()\nplot(polys, col = \"lightgrey\", lwd = 0.5, border = 'white', \n     main = \"Cumulative lag-2 adjacency\")\nplot(nb, pts, col = 'red', lwd = 0.5, add = TRUE)\n\n\n\n\n\n\n\nk-nearest neighbours\nNote that we use the centroids (pts_c) to calculate the distances, but the points inside the polygons (pts) from st_point_on_surface() for the plotting.\n\n\nCode\nlayout(matrix(1:3, ncol = 3, byrow = TRUE))\npar(mai = c(0, 0, 0.15, 0))\n\nnb &lt;- pts_c %&gt;% knearneigh(k = 3) %&gt;% knn2nb()\nplot(polys, col = \"lightgrey\", lwd = 0.5, border = 'white', \n     main = \"k = 3\")\nplot(nb, pts, col = 'red', lwd = 0.5, add = TRUE)\n\nnb &lt;- pts_c %&gt;% knearneigh(k = 6) %&gt;% knn2nb()\nplot(polys, col = \"lightgrey\", lwd = 0.5, border = 'white', \n     main = \"k = 6\")\nplot(nb, pts, col = 'red', lwd = 0.5, add = TRUE)\n\nnb &lt;- pts_c %&gt;% knearneigh(k = 12) %&gt;% knn2nb()\nplot(polys, col = \"lightgrey\", lwd = 0.5, border = 'white', \n     main = \"k = 12\")\nplot(nb, pts, col = 'red', lwd = 0.5, add = TRUE)\n\n\n\n\n\n\n\nDistance criteria\nNext, distance criteria, again calculated from centroids, but visualised using the st_point_on_surface().\n\n\nCode\nlayout(matrix(1:3, ncol = 3, byrow = TRUE))\npar(mai = c(0, 0, 0.15, 0))\n\nnb &lt;- pts_c %&gt;% dnearneigh(d1 = 0, d2 = 1000)\nplot(polys, col = \"lightgrey\", lwd = 0.5, border = 'white', \n     main = \"Distance &lt; 1000\")\nplot(nb, pts, col = 'red', lwd = 0.5, add = TRUE)\n\nnb &lt;- pts_c %&gt;% dnearneigh(d1 = 0, d2 = 1500)\nplot(polys, col = \"lightgrey\", lwd = 0.5, border = 'white', \n     main = \"Distance &lt; 1500\")\nplot(nb, pts, col = 'red', lwd = 0.5, add = TRUE)\n\nnb &lt;- pts_c %&gt;% dnearneigh(d1 = 1500, d2 = 2000)\nplot(polys, col = \"lightgrey\", lwd = 0.5, border = 'white', \n     main = \"1500 &lt; Distance &lt; 2000\")\nplot(nb, pts, col = 'red', lwd = 0.5, add = TRUE)\n\n\n\n\n\n\n\nGraph-based approaches\nFinally, some network-based possibilities, Delaunay triangulation, Gabriel graph and the relative neighbour graph.\n\n\nCode\nlayout(matrix(1:3, ncol = 3, byrow = TRUE))\npar(mai = c(0, 0, 0.15, 0))\n\ng &lt;- tri2nb(pts_c)\nplot(polys, col = \"lightgrey\", lwd = 0.5, border = 'white', \n     main = \"Delaunay triangulation\")\nplot(g, pts, col = 'red', lwd = 0.5, add = TRUE)\n\ng &lt;- gabrielneigh(pts_c)\nnb &lt;- graph2nb(g)\nplot(polys, col = \"lightgrey\", lwd = 0.5, border = 'white', \n     main = \"Gabriel graph\")\nplot(nb, pts, col = 'red', lwd = 0.5, add = TRUE)\n\ng &lt;- relativeneigh(pts_c)\nnb &lt;- graph2nb(g)\nplot(polys, col = \"lightgrey\", lwd = 0.5, border = 'white', \n     main = \"Relative neighbour graph\")\nplot(nb, pts, col = 'red', lwd = 0.5, add = TRUE)\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "chapters/chap5/fig5-07-maup-aggregation.html",
    "href": "chapters/chap5/fig5-07-maup-aggregation.html",
    "title": "Figure 5.7: The MAUP aggregation effect",
    "section": "",
    "text": "This page produces a coloured version of Figure 5.7 which may be a little easier to read. It also uses standard deviation ellipses to make things a bit clearer (I hope).\nCode\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(tidyverse)\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap5/fig5-07-maup-aggregation.html#data",
    "href": "chapters/chap5/fig5-07-maup-aggregation.html#data",
    "title": "Figure 5.7: The MAUP aggregation effect",
    "section": "Data",
    "text": "Data\n\nMake a correlated dataset\nUsing the MASS::mvrnorm() function we can create a dataframe with x and y variables with some requested correlation. We also reorder by the sum of the two variables (in effect from lower-left to upper-right), and number the observations on that basis. This allows us to aggregate observations that are broadly similar or broadly different.\n\n\nCode\nget_correlated_df &lt;- function(cor = 0.5) {\n  # generate a multivariate normal distribution\n  # mu is the mean centre, Sigma is the covariance matrix\n  mvrnorm(n = 1024, mu = c(5, 5), \n          Sigma = matrix(c(1, cor, cor, 1), 2, 2)) %&gt;%\n    as.data.frame() %&gt;%\n    rename(x = V1, y = V2) %&gt;%\n    arrange(x + y) %&gt;% \n    mutate(id = row_number())\n}\n\n\n\n\nAggregator functions\nNext two functions that aggregate either similar or different observations. This is a fairly crude approach but it works. agg_similar() uses integer division to create a ‘grouper’ variable that goes eight 0s, then eight 1s, then eight 2s, and so on up to eight 127s. When group_by is applied using this variable, sets of 8 similar observations are aggregated and the mean taken to give a new dataset.\nConversely, if the grouper variable is based on the remainder from division by 128, we get 8 sequences of 0, 1, 2, 3,… 127, and when these are aggregated into groups, each will consist of eight observations at widely separated positions in the sequence (i.e., with very different values).\n\n\nCode\n# aggregate similar observations\nagg_similar &lt;- function(df) {\n  df %&gt;%\n    mutate(grouper = id %/% 8) %&gt;%\n    group_by(grouper) %&gt;%\n    summarise(x = mean(x), \n              y = mean(y)) %&gt;%\n    dplyr::select(-grouper) %&gt;%\n    ungroup()\n}\n\n# aggregate different observations\nagg_different &lt;- function(df) {\n  df %&gt;%\n    mutate(grouper = id %% 128) %&gt;%\n    group_by(grouper) %&gt;%\n    summarise(x = mean(x), \n              y = mean(y)) %&gt;%\n    dplyr::select(-grouper) %&gt;%\n    ungroup()\n}"
  },
  {
    "objectID": "chapters/chap5/fig5-07-maup-aggregation.html#plotting-functions",
    "href": "chapters/chap5/fig5-07-maup-aggregation.html#plotting-functions",
    "title": "Figure 5.7: The MAUP aggregation effect",
    "section": "Plotting functions",
    "text": "Plotting functions\nWe also make some plotting functions so we don’t have to repeat a lot of code. These add three plots based on a dataset. A scatterplot of the points, a standard deviation ellipse, and a best fit line. This will make sense when you see the plots.\n\n\nCode\nadd_df_plots &lt;- function(g, df, colour, alpha_pts = 0.5, \n                         alpha_ellipse_fill = 0.25, polygon = TRUE) {\n  g &lt;- g + \n    geom_point(data = df, aes(x = x, y = y),\n               colour = colour, alpha = alpha_pts, pch = 16, size = 1)\n  if (polygon) {\n    g &lt;- g + \n      stat_ellipse(data = df, aes(x = x, y = y),\n                   geom = \"polygon\", alpha = alpha_ellipse_fill, fill = colour)\n  } else {\n    g &lt;- g + \n      stat_ellipse(data = df, aes(x = x, y = y), colour = colour, linewidth = 0.35)\n  }\n  g + geom_smooth(data = df, aes(x = x, y = y),\n                  method = lm, se = FALSE, colour = colour, linewidth = 0.5)\n}\n\nthree_plots &lt;- function(df1, df2, df3) {\n  g &lt;- ggplot()\n  g &lt;- add_df_plots(g, df1, \"black\", alpha_pts = 0.2, polygon = FALSE)\n  g &lt;- add_df_plots(g, df2, \"forestgreen\")\n  g &lt;- add_df_plots(g, df3, \"violet\")\n  g + coord_equal() + theme_void()\n}"
  },
  {
    "objectID": "chapters/chap5/fig5-07-maup-aggregation.html#finally-the-plots",
    "href": "chapters/chap5/fig5-07-maup-aggregation.html#finally-the-plots",
    "title": "Figure 5.7: The MAUP aggregation effect",
    "section": "Finally the plots",
    "text": "Finally the plots\nSo now make some datsets and see what we get.\nFirst a dataset with approximage correlation between x and y of 0.5. We then aggregate it two ways and plot the results.\n\n\nCode\ndf &lt;- get_correlated_df(0.5)\ndf_sim &lt;- df %&gt;%\n  agg_similar()\ndf_diff &lt;- df %&gt;%\n  agg_different()\n\nthree_plots(df, df_sim, df_diff)\n\n\n\n\n\nWhen we aggregate similar observations (the green ellipse) the correlation is increased, while aggregating different observations inverts the correlation (the violet ellipse)! The initial correlation is seen in the unfilled black ellipse.\nThe effect is even more remarkable for uncorrelated data:\n\n\nCode\ndf &lt;- get_correlated_df(0)\ndf_sim &lt;- df %&gt;%\n  agg_similar()\ndf_diff &lt;- df %&gt;%\n  agg_different()\n\nthree_plots(df, df_sim, df_diff)\n\n\n\n\n\nWhat do we take from this in a geographical setting? Well, if indeed “near things are more related than distant things”, then in many situations where data are aggregated spatially based on proximity positive correlations are likely to be ‘enhanced’, and we may even see correlations where none exist at the individual level.\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "chapters/chap5/fig5-01-9-intersection.html",
    "href": "chapters/chap5/fig5-01-9-intersection.html",
    "title": "Figure 5.1: The 9-intersection model of topological relations",
    "section": "",
    "text": "This page attempts to show the various spatial predicates of the 9-intersection model presented in Figure 5.1 in code.\nFirst we make some shapes, and map them.\n\n\nCode\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tmap)\nlibrary(stringr)\n\np1 &lt;- st_point(c(-2, 0)) %&gt;% st_buffer(1, nQuadSegs = 90)\np2 &lt;- p1\np3 &lt;- p1 + c(2, 0)\np4 &lt;- p3 * matrix(c(0.5, 0, 0, 0.5), 2, 2)\np5 &lt;- p4 + c(0, -0.5)\np6 &lt;- st_difference(p3, p4) + c(2.1, 0)\np7 &lt;- p4 * matrix(c(1.5, 0, 0, 1.5), 2, 2) + c(2, -1)\n\npolys &lt;- st_sfc(list(p1, p2, p3, p4, p5, p6, p7)) %&gt;% \n  st_sf() %&gt;%\n  mutate(ID = 1:7, \n         dx = c(0, 0, .5, 0, 0, 0, 0), \n         dy = c(-1, 1, 2, 0, 0, 0, 0))\n\n\nMap and label these for reference.\n\n\nCode\nlines &lt;- polys %&gt;% st_cast(\"MULTILINESTRING\") # for placing text labels\n\ntm_shape(polys) + \n  tm_fill(col = \"ID\", alpha = 0.5, style = \"cat\", \n          palette = c(\"red\", \"dodgerblue3\", \"darkgreen\", \n                      \"black\", \"yellow\", \"violet\", \"brown\"),\n          legend.is.portrait = FALSE) +\n  tm_shape(lines) +\n  tm_text(text = \"ID\", xmod = \"dx\", ymod = \"dy\") +\n  tm_layout(\n    frame = FALSE, legend.outside = TRUE,\n    legend.outside.position = \"bottom\", \n    legend.position = c(0.5, 0.5), \n    legend.just = c(0.5, 0.5))\n\n\n\n\n\nNow we can run various tests against the spatial predicates in turn. For example st_disjoint tells us the following.\n\n\nCode\npolys %&gt;% st_disjoint()\n\n\nSparse geometry binary predicate list of length 7, where the predicate\nwas `disjoint'\n 1: 3, 4, 5, 6, 7\n 2: 3, 4, 5, 6, 7\n 3: 1, 2, 6, 7\n 4: 1, 2, 6, 7\n 5: 1, 2, 6, 7\n 6: 1, 2, 3, 4, 5\n 7: 1, 2, 3, 4, 5\n\n\nWe can tabulate the result of applying all the spatial predicates to these polygons into a table.\nThe details of how this is done don’t matter greatly, but if you are interested click into the code below. The core of it is based on the various st_* functions such as st_intersects or st_contains. These correspond, more or less to the relations identified in Figure 5.1. The spatial predicates available in the sf package in R correspond to those implemented in spatial databases such as PostGIS.\n\n\nCode\nget_spatial_query_as_vector &lt;- function(data, predicate) {\n  data %&gt;% \n    predicate() %&gt;%\n    lapply(str_c, collapse = \" \") %&gt;%\n    unlist()\n}\n\nde9im &lt;- data.frame(\n  ID = polys$ID,\n  disjoint          = get_spatial_query_as_vector(polys, st_disjoint),\n  touches           = get_spatial_query_as_vector(polys, st_touches),\n  equals            = get_spatial_query_as_vector(polys, st_equals),\n  intersects        = get_spatial_query_as_vector(polys, st_intersects),\n  contains_properly = get_spatial_query_as_vector(polys, st_contains_properly),\n  contains          = get_spatial_query_as_vector(polys, st_contains),\n  within            = get_spatial_query_as_vector(polys, st_within),\n  covers            = get_spatial_query_as_vector(polys, st_covers),\n  covered_by        = get_spatial_query_as_vector(polys, st_covered_by)\n)\n\nknitr::kable(de9im)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID\ndisjoint\ntouches\nequals\nintersects\ncontains_properly\ncontains\nwithin\ncovers\ncovered_by\n\n\n\n\n1\n3 4 5 6 7\n\n1 2\n1 2\n\n1 2\n1 2\n1 2\n1 2\n\n\n2\n3 4 5 6 7\n\n1 2\n1 2\n\n1 2\n1 2\n1 2\n1 2\n\n\n3\n1 2 6 7\n\n3\n3 4 5\n4\n3 4 5\n3\n3 4 5\n3\n\n\n4\n1 2 6 7\n\n4\n3 4 5\n\n4\n3 4\n4\n3 4\n\n\n5\n1 2 6 7\n\n5\n3 4 5\n\n5\n3 5\n5\n3 5\n\n\n6\n1 2 3 4 5\n\n6\n6 7\n\n6\n6\n6\n6\n\n\n7\n1 2 3 4 5\n\n7\n6 7\n\n7\n7\n7\n7\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap5/index.html",
    "href": "chapters/chap5/index.html",
    "title": "Chapter 5",
    "section": "",
    "text": "Lines are more or less the defining characteristic of maps, invested with all kinds of meaning, not least the demarcation of nation states, properties, and all kinds of administrative entities. In giscience this is recognised most obviously in the modifiable areal unit problem, setting to one side many of the deeper questions that the arbitrariness of such lines—their fiat nature raises (see §Fiat and Bona Fide Boundaries and Objects in particular).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinks for Chapter 5\n\n\n\nlinks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.1: The 9-intersection model of topological relations\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.5: Maps of areas with widely varying populations\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.6: Simple illustration of the modifiable areal unit problem\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.7: The MAUP aggregation effect\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap5/fig5-05-ca-pop-maps.html",
    "href": "chapters/chap5/fig5-05-ca-pop-maps.html",
    "title": "Figure 5.5: Maps of areas with widely varying populations",
    "section": "",
    "text": "Not too much to say here, except that it would be nice if somebody would develop a better approach to mapping US-wide data. Counties really are a terrible base unit.\n\n\nCode\nlibrary(sf)\nlibrary(tmap)\nlibrary(dplyr)\n\nca &lt;- st_read(\"ca-pops.gpkg\")\n\nm1 &lt;- tm_shape(ca) + \n  tm_fill(col = \"population\", \n          title = \"Population\", palette = \"Reds\") +\n  tm_borders(col = \"white\", lwd = 0.5) + \n  tm_legend(position = c(\"left\", \"bottom\")) +\n  tm_layout(frame = FALSE, legend.width = 0.5)\n  \nm2 &lt;- tm_shape(ca) + \n  tm_fill(col = \"population\", convert2density = TRUE, \n          title = \"Pop density\", palette = \"Greens\") +\n  tm_borders(col = \"white\", lwd = 0.5) + \n  tm_legend(position = c(\"left\", \"bottom\")) +\n  tm_layout(frame = FALSE, legend.width = 0.5)\n\nm3 &lt;- tm_shape(ca) + \n  tm_fill(col = \"population\", convert2density = TRUE, \n          title = \"Pop density\", style = \"log10_pretty\", \n          palette = \"Blues\") +\n  tm_borders(col = \"white\", lwd = 0.5) + \n  tm_legend(position = c(\"left\", \"bottom\")) +\n  tm_layout(frame = FALSE, legend.width = 0.5)\n  \ntmap_arrange(m1, m2, m3)\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap5/links-5.html",
    "href": "chapters/chap5/links-5.html",
    "title": "Links for Chapter 5",
    "section": "",
    "text": "This Figure is a section of the map of the Cooch Behar enclave complex, available at commons.wikimedia.org. Highly detailed maps of the enclave complex are available in Brendan Whyte’s PhD thesis available here.\n\n\n\nThe data for this Figure are at the link noted in the Figure caption github.com/lucguillemot/bayareageodemo. There’s an interactive map at lucguillemot.github.io/bayareageodemo/. The map was designed by the very talented Luc Guillemot.\n\n\n\nThe Manaaki Whenua Landcare Research’s Land Environments of New Zealand website is at landcareresearch.co.nz/tools-and-resources/mapping/lenz/. Input data layers on which the LENZ classification was based are available at lris.scinfo.org.\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap5/links-5.html#links",
    "href": "chapters/chap5/links-5.html#links",
    "title": "Links for Chapter 5",
    "section": "",
    "text": "This Figure is a section of the map of the Cooch Behar enclave complex, available at commons.wikimedia.org. Highly detailed maps of the enclave complex are available in Brendan Whyte’s PhD thesis available here.\n\n\n\nThe data for this Figure are at the link noted in the Figure caption github.com/lucguillemot/bayareageodemo. There’s an interactive map at lucguillemot.github.io/bayareageodemo/. The map was designed by the very talented Luc Guillemot.\n\n\n\nThe Manaaki Whenua Landcare Research’s Land Environments of New Zealand website is at landcareresearch.co.nz/tools-and-resources/mapping/lenz/. Input data layers on which the LENZ classification was based are available at lris.scinfo.org."
  },
  {
    "objectID": "chapters/chap5/fig5-06-simple-maup.html",
    "href": "chapters/chap5/fig5-06-simple-maup.html",
    "title": "Figure 5.6: Simple illustration of the modifiable areal unit problem",
    "section": "",
    "text": "I’ve remade this one in colour, because I think it’s a bit easier to see this way.\nSome libraries:\n\n\nCode\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tmap)\nlibrary(MASS)\n\n\nWe need to make a grid of values, with a clear gradient in one direction. The code for making geometries in R is ugly, so I’ve hidden it.\n\n\nCode\nmake_square &lt;- function(x = 0, y = 0, d = 1) {\n  xs &lt;- x + c(-1, 1, 1, -1) * d / 2\n  ys &lt;- y + c(-1, -1, 1, 1) * d / 2\n  xs &lt;- c(xs, xs[1])\n  ys &lt;- c(ys, ys[1])\n  st_polygon(list(matrix(c(xs, ys), ncol = 2)))\n}\n\ngrid &lt;- expand.grid(1:10, 1:10)\n\npolys &lt;- list()\nfor (r in 1:nrow(grid)) {\n  polys &lt;- c(polys, make_square(x = grid[r, 1], y = grid[r, 2]))\n}\n\npoly_sf &lt;- polys %&gt;% \n  lapply(list) %&gt;%\n  lapply(st_polygon) %&gt;%\n  st_sfc() %&gt;%\n  st_sf(x = grid[, 1], y = grid[, 2])\nn &lt;- dim(poly_sf)[1]\npoly_sf$val &lt;- poly_sf$x + runif(n, -0.5, 0.5)\n\n\nAnyway… we have a 10 by 10 grid of squares with values that increase from left to right:\n\n\nCode\nbrks &lt;- .5 + (0:100) / 10\n\ntm_shape(poly_sf) +\n  tm_polygons(col = \"val\", palette = \"Spectral\", breaks = brks, lwd = 0.5) +\n  tm_layout(frame = FALSE, legend.show = FALSE)\n\n\n\n\n\nNow we aggregate into columns and rows, taking the mean value of our variable in each case.\n\n\nCode\ncolumn_sf &lt;- poly_sf %&gt;%\n  group_by(x) %&gt;%\n  summarise(val = mean(val)) \n\nrows_sf &lt;- poly_sf %&gt;%\n  group_by(y) %&gt;%\n  summarise(val = mean(val))\n\n\nAnd now we can make maps of the results. The column-wise aggregation emphasizes the gradient, while the row-wise aggregation erases it completely, since every row has a similar set of values ranging from low to high, and when these are combined each row ends up pretty much the same.\n\n\nCode\nm1 &lt;- tm_shape(column_sf) +\n  tm_polygons(col = \"val\", palette = \"Spectral\", breaks = brks, lwd = 0.5) +\n  tm_layout(frame = FALSE, legend.show = FALSE)\n\nm2 &lt;- tm_shape(rows_sf) +\n  tm_polygons(col = \"val\", palette = \"Spectral\", breaks = brks, lwd = 0.5) +\n  tm_layout(frame = FALSE, legend.show = FALSE)\n\ntmap_arrange(list(m1, m2), nrow = 1)\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap9/index.html",
    "href": "chapters/chap9/index.html",
    "title": "Chapter 9",
    "section": "",
    "text": "Finally, a (very) modest proposal—more of a plea really—that we all pay more attention to each other’s work and perspectives, and take seriously the idea that giscience is geographical in how we educate both ‘GISers’ and geographers.\n\n\n\n\n\n\n\n\n\nNo matching items\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap7/fig7-02-7-03-tg-aquarium.html",
    "href": "chapters/chap7/fig7-02-7-03-tg-aquarium.html",
    "title": "Figures 7.2 and 7.3: Goings on in the space-time aquarium",
    "section": "",
    "text": "Code\nlibrary(dplyr)\nlibrary(plotly)\nlibrary(plot3D)\n\n\n\n\nCode\ntime_space_data &lt;- read.csv(\"tg-day-in-the-life.csv\")\n\nlocations_0 &lt;- unique(select(time_space_data, x, y)) %&gt;%\n  mutate(id = 1:5, t = 0)\nlocations_24 &lt;- locations_0 %&gt;%\n  mutate(t = 24)\n\nlines3D(time_space_data$x, time_space_data$y, time_space_data$t, \n        xlim = c(min(time_space_data$x) - 2, \n                 max(time_space_data$x) + 2),\n        ylim = c(min(time_space_data$y) - 2, \n                 max(time_space_data$y) + 2),\n        xlab = \"x\", ylab = \"y\", zlab = \"Time, t\",\n        col = \"#00000080\", lwd = 2, alpha = 0.5, \n        phi = 25, theta = 60, bty = \"g\", scale = FALSE)\n\npoints3D(locations_0$x, locations_0$y, locations_0$t, \n         add = TRUE, col = \"black\")\n\narrows3D(locations_0$x, locations_0$y, locations_0$t, \n         locations_24$x, locations_24$y, locations_24$t, \n         add = TRUE, lty = \"dashed\", lwd = 0.5, col = \"black\")\n\n\n\n\n\n\n\nCode\ntime_space_data &lt;- read.csv(\"tg-meeting.csv\")\n\ntrace &lt;- time_space_data %&gt;% \n  filter(id == 1)\n\nlines3D(trace$x, trace$y, trace$t, \n        xlim = c(-6, 6), ylim = c(-6, 6),\n        xlab = \"x\", ylab = \"y\", zlab = \"Time, t\",\n        col = \"black\", lwd = .5, phi = 25, theta = 60, \n        bty = \"g\", scale = FALSE)\n\nfor (i in 2:8) {\n  trace &lt;- time_space_data %&gt;% filter(id == i)\n  lines3D(trace$x, trace$y, trace$t, add = TRUE,\n          xlim = c(-6, 6), ylim = c(-6, 6),\n          col = \"black\", lwd = .5)\n}\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap7/index.html",
    "href": "chapters/chap7/index.html",
    "title": "Chapter 7",
    "section": "",
    "text": "If space and place are geography’s in-house terrible twins then time is its estranged first cousin. The notion of a space-time-attribute hyperspace wherein geography examines fixed time slices, while history focuses on fixed localities over time is firmly embedded in giscience given its origins in automated cartography and the snapshot view of the world implicit in maps. Time geography a possible escape from this impasse, and, I would argue is central to both human dynamics and mobilities perspectives, although those two subfields of contemporary geography remain frustratingly distant from one another.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinks for Chapter 7\n\n\n\nlinks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigures 7.2 and 7.3: Goings on in the space-time aquarium\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap7/links-7.html",
    "href": "chapters/chap7/links-7.html",
    "title": "Links for Chapter 7",
    "section": "",
    "text": "The ‘timebliography’ of representations of time in giscience is available at http://spaceandtime.wsiabato.info/ (yes http, not https).\n\n\n\nThe taxi trajectory dataset is available at microsoft.com/en-us/research/publication/t-drive-trajectory-data-sample.\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap7/links-7.html#links",
    "href": "chapters/chap7/links-7.html#links",
    "title": "Links for Chapter 7",
    "section": "",
    "text": "The ‘timebliography’ of representations of time in giscience is available at http://spaceandtime.wsiabato.info/ (yes http, not https).\n\n\n\nThe taxi trajectory dataset is available at microsoft.com/en-us/research/publication/t-drive-trajectory-data-sample."
  },
  {
    "objectID": "chapters/chap6/fig6-14-sb-drive-time.html",
    "href": "chapters/chap6/fig6-14-sb-drive-time.html",
    "title": "Figure 6.14: Relative time map of the Santa Barbara street network",
    "section": "",
    "text": "This started out as the notebook developed by Geoff Boeing available here although by now it has been very heavily modified!\nI was lucky enough to co-advise Geoff as a PhD student at Berkeley, and when he announced that he was going to build osmnx as part of his project—only a part, mind!—I did the proper thing and expressed concern that he was being overly ambitious. PhD advising is mostly about steering students towards the possible, and reining in their wilder ideas… at least that is the common wisdom. So much for that: Geoff built it and the rest is (niche) history.\n[If I have one criticism of osmnx it is that the code gets updated so often that function names are subject to rapid change. You may find that some of what follows doesn’t work in more recent versions than 1.6.0.]\nAnyway… as usual we need some libraries:\n\n\nCode\nimport math\nimport pandas\nimport geopandas\nimport matplotlib.pyplot as plt\nimport networkx\nimport igraph\nimport osmnx\nfrom shapely.geometry import Point\n\nosmnx.settings.log_console = True\nosmnx.settings.use_cache = True\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap6/fig6-14-sb-drive-time.html#travel-time-based-reprojection-of-a-network",
    "href": "chapters/chap6/fig6-14-sb-drive-time.html#travel-time-based-reprojection-of-a-network",
    "title": "Figure 6.14: Relative time map of the Santa Barbara street network",
    "section": "",
    "text": "This started out as the notebook developed by Geoff Boeing available here although by now it has been very heavily modified!\nI was lucky enough to co-advise Geoff as a PhD student at Berkeley, and when he announced that he was going to build osmnx as part of his project—only a part, mind!—I did the proper thing and expressed concern that he was being overly ambitious. PhD advising is mostly about steering students towards the possible, and reining in their wilder ideas… at least that is the common wisdom. So much for that: Geoff built it and the rest is (niche) history.\n[If I have one criticism of osmnx it is that the code gets updated so often that function names are subject to rapid change. You may find that some of what follows doesn’t work in more recent versions than 1.6.0.]\nAnyway… as usual we need some libraries:\n\n\nCode\nimport math\nimport pandas\nimport geopandas\nimport matplotlib.pyplot as plt\nimport networkx\nimport igraph\nimport osmnx\nfrom shapely.geometry import Point\n\nosmnx.settings.log_console = True\nosmnx.settings.use_cache = True"
  },
  {
    "objectID": "chapters/chap6/fig6-14-sb-drive-time.html#download-and-prep-the-street-network",
    "href": "chapters/chap6/fig6-14-sb-drive-time.html#download-and-prep-the-street-network",
    "title": "Figure 6.14: Relative time map of the Santa Barbara street network",
    "section": "Download and prep the street network",
    "text": "Download and prep the street network\nWhat osmnx excels at is pulling (generally messy) street network data and cleaning it up for analysis. Here’s how it works:\n\n\nCode\n# configure the place, network type, trip times, and travel speed\nplace = \"Santa Barbara, California\"\nnetwork_type = \"drive\"\n\nG = osmnx.graph_from_place(place, network_type = network_type)\n\n\nThe network needs to be connected for any of the following to work reliably, so we extract the largest component and throw away everything else. I can’t vouch for this being the best way to accomplish this, but it seems to work.\n\n\nCode\nG = G.to_undirected() # required for extraction of giant component\n\nGcc = sorted(networkx.connected_components(G), key = len, reverse = True)\nG = G.subgraph(Gcc[0]).copy()\n\n\n\nSome geography stuff…\nThis line will project the data to an appropriate UTM projection, and then we can make an appropriately UTM projected geopandas.GeoDataFrame.\n\n\nCode\nG = osmnx.project_graph(G)\ngdf_nodes = osmnx.graph_to_gdfs(G, edges = False)\nCRS = gdf_nodes.crs\n\n\nNext we make a convex hull of the nodes, and determine its centroid, then use this to find the node nearest the centroid. We also make a simple GeoSeries so we can check what we’ve done makes sense.\n\n\nCode\nconvex_hull = gdf_nodes[\"geometry\"].unary_union.convex_hull\nx, y = convex_hull.centroid.xy\ncentre_node = osmnx.distance.nearest_nodes(G, x[0], y[0])\np1 = geopandas.GeoSeries([Point(x[0], y[0])])\np2 = geopandas.GeoSeries(Point(G.nodes[centre_node][\"x\"],\n                               G.nodes[centre_node][\"y\"]))\n\n\nAnd we can make a sanity check plot\n\n\nCode\nax = gdf_nodes.plot(markersize = 0.75, figsize = (8, 16))\n\ngeopandas.GeoSeries([convex_hull]).plot(ax = ax, fc = \"#00000000\", ec = \"k\")\np1.plot(ax = ax, marker = \"o\", markersize = 50, color = \"k\")\np2.plot(ax = ax, marker = \"x\", markersize = 80, color = \"r\")\n\n\n&lt;Axes: &gt;"
  },
  {
    "objectID": "chapters/chap6/fig6-14-sb-drive-time.html#handling-the-edge-travel-times",
    "href": "chapters/chap6/fig6-14-sb-drive-time.html#handling-the-edge-travel-times",
    "title": "Figure 6.14: Relative time map of the Santa Barbara street network",
    "section": "Handling the edge travel times",
    "text": "Handling the edge travel times\nThe data in OSM networks is fairly ad hoc in this regard, so the below has been assembled by trial and error. There may be better tools available for cleaning up network data attributes.\nWe assume a default_speed of 30 km/h expressed in metres per minute (i.e. 500!). Where we find maximum speed information in the data we use that instead.\nWe assume a delay at intersections—this might not make total sense, but slows things down on major arterials.\nspeed_units_per_metre is the maxspeed attribute from OSM and for most jurisdictions is km, so 0.001 per metre.\n\n\nCode\ndefault_speed = 30 * 1000 / 60 # default driving speed in m / min\nintersection_delay = .33 # wait time at intersection in minutes\nunits_per_metre = 0.001\n\n\nSome hackery below to convert appropriately if maxspeed is missing or is a list of some kind or is expressed in mph.\n\n\nCode\n# add an edge attribute for time in minutes required to traverse each edge\nfor data in G.edges.values():\n    len_seg = data[\"length\"]\n    data[\"time\"] = len_seg / default_speed\n    if \"maxspeed\" in data:\n        max_speed = data[\"maxspeed\"]\n        if type(max_speed) is list:\n            max_speed = max_speed[0]\n        if \";\" in max_speed:\n            max_speed = max_speed.split(\";\")[0]\n        if \"mph\" in max_speed:\n            max_speed = max_speed.split()[0]\n            units_per_metre = 0.0006213712\n        if max_speed.isnumeric():\n            max_speed = float(max_speed)\n        data[\"time\"] = len_seg * units_per_metre / max_speed * 60\n    data[\"time\"] += intersection_delay\n\n\n\nCalculate node distances from centre node\nNow we can determine network travel times from our centre node to every other node. While assembling this notebook I encountered a problem with the networkx function single_source_path_length() function, which can be unreliable with floating point edge weights (in this cast the time attribute). As a workaround I am using igraph instead.\n\n\nCode\ncentre_node_index = [n for n in G.nodes].index(centre_node)\niG = igraph.Graph.from_networkx(G)\niG.vs[centre_node_index]\n\nnode_travel_times = dict(zip(\n  G.nodes, \n  iG.distances([centre_node_index], weights = \"time\", mode = \"all\")[0]))\n\n\nWe also need the bearings of every node from the centre node.\n\n\nCode\n# Assume that nodes have x and y attributes and these are in a projected\n# coordinate system such that simple trigonometry will give bearing\ndef bearing(G, n0, n1):\n    N0 = G.nodes[n0]\n    N1 = G.nodes[n1]\n    return n1, \\\n        math.atan2((N1[\"y\"] - N0[\"y\"]), (N1[\"x\"] - N0[\"x\"]))\n                 \nnode_bearings = dict(\n  [bearing(G, centre_node, n) for n in node_travel_times.keys()])\n\n\nand… a function to return \\(x\\) and \\(y\\) offsets from the centre node, given their distance and bearing.\n\n\nCode\ndef dxdy(d, b):\n    return d * math.cos(b), d * math.sin(b)\n\n\n\n\nDictionary of x y offsets from centre node indexed by node\nKeep in mind distances are now travel time based, while bearings remain ‘true’, so that less accessible locations are pushed farther from centre, and more accessible ones pulled nearer in the direction of the bearting. Note that all angles here are in radians.\n\n\nCode\nnode_dxdys = dict(\n  [(n, dxdy(node_travel_times[n], node_bearings[n])) \n   for n in node_travel_times.keys()])\n\n\n\n\nPut all this in a table for safe keeping!\n\n\nCode\nimport pandas\ndf_nodes = pandas.DataFrame(data = {\"osmid\": list(node_travel_times.keys())})\n\ndf_nodes[\"tx\"] = [node_dxdys[i][0] for i in df_nodes.osmid]\ndf_nodes[\"ty\"] = [node_dxdys[i][1] for i in df_nodes.osmid]\ndf_nodes[\"x\"] = [G.nodes[i][\"x\"] for i in df_nodes.osmid]\ndf_nodes[\"y\"] = [G.nodes[i][\"y\"] for i in df_nodes.osmid]\ndf_nodes[\"time\"] = [node_travel_times[i] for i in df_nodes.osmid]\n\ndf_nodes.head()\n\n\n\n\n\n\n\n\n\nosmid\ntx\nty\nx\ny\ntime\n\n\n\n\n0\n164707756\n-10.095840\n0.516131\n248112.235570\n3.813112e+06\n10.109025\n\n\n1\n164707812\n-10.891007\n-0.676010\n247856.180584\n3.812756e+06\n10.911967\n\n\n2\n165442802\n-10.533059\n0.734952\n248000.588151\n3.813176e+06\n10.558668\n\n\n3\n1467958591\n-9.136781\n-0.608773\n248676.344687\n3.812796e+06\n9.157039\n\n\n4\n165337776\n-11.392333\n-0.672562\n247771.128942\n3.812761e+06\n11.412169\n\n\n\n\n\n\n\nWrite this out to disk and read it back in. This means you can start here next time if you prefer…\n\n\nCode\ndf_nodes.to_csv(\"nodes.csv\", index = False)\ndf_nodes = pandas.read_csv(\"nodes.csv\")"
  },
  {
    "objectID": "chapters/chap6/fig6-14-sb-drive-time.html#now-make-geodataframes-and-maps",
    "href": "chapters/chap6/fig6-14-sb-drive-time.html#now-make-geodataframes-and-maps",
    "title": "Figure 6.14: Relative time map of the Santa Barbara street network",
    "section": "Now make GeoDataFrames and maps",
    "text": "Now make GeoDataFrames and maps\nThis is pretty simple now we have all the data.\n\n\nCode\nn_gdf_xy = geopandas.GeoDataFrame(\n  data = df_nodes[[\"time\"]], \n  geometry = geopandas.GeoSeries(\n    [Point(p[0], p[1]) for p in zip(df_nodes.x, df_nodes.y)]))\nn_gdf_xy.set_crs(CRS)\n\nn_gdf_txty = geopandas.GeoDataFrame(\n  data = df_nodes[[\"time\"]],\n  geometry = geopandas.GeoSeries(\n    [Point(p[0], p[1]) for p in zip(df_nodes.tx, df_nodes.ty)]))\n\n\nAnd make two maps of the nodes.\n\n\nCode\nfig = plt.figure(figsize = (16, 8))\n\nax = fig.add_subplot(121)\nn_gdf_xy.plot(ax = ax, column = \"time\", markersize = 2)\nax.set_title(\"Santa Barbara in geodetic space\")\n\nax = fig.add_subplot(122)\nn_gdf_txty.plot(ax = ax, column = \"time\", markersize = 2)\nax.set_title(\"Santa Barbara in drivetime space\")\n\n\nText(0.5, 1.0, 'Santa Barbara in drivetime space')"
  },
  {
    "objectID": "chapters/chap6/fig6-14-sb-drive-time.html#plots-that-include-the-edges",
    "href": "chapters/chap6/fig6-14-sb-drive-time.html#plots-that-include-the-edges",
    "title": "Figure 6.14: Relative time map of the Santa Barbara street network",
    "section": "Plots that include the edges",
    "text": "Plots that include the edges\n\nStandard map\nThe geodetic one is easy—just use the osmnx plotting function\n\n\nCode\nosmnx.plot_graph(G, node_color = \"k\", node_size = 2, figsize = (12, 8),\n                           edge_color = \"k\", edge_linewidth = 0.5, \n                           bgcolor = \"w\")\n\n\n\n\n\n(&lt;Figure size 1200x800 with 1 Axes&gt;, &lt;Axes: &gt;)\n\n\n\n\nTime based is trickier…\nFirst we need to make a new graph with the time based positions as the node positions\n\n\nCode\nG_time = G.copy()\n\nfor n, dxdy in node_dxdys.items():\n    G_time.nodes()[n][\"x\"] = dxdy[0]\n    G_time.nodes()[n][\"y\"] = dxdy[1]\n\n\nNow… for reasons unclear to me, simply plotting this using osmnx will not work—presumably (yet again!) something to do with projections. Instead we need to make a matplotlib LineCollection and plot that… so here goes…\n\n\nCode\n# define the plot limits\nnode_xs = [float(n[\"x\"]) for n in G_time.nodes.values()]\nnode_ys = [float(n[\"y\"]) for n in G_time.nodes.values()]\n\nW, S, E, N = (min(node_xs) - 1, min(node_ys) - 1,\n              max(node_xs) + 1, max(node_ys) + 1)\nbbox_aspect = (N - S) / (E - W)\nfig_h = 12\nfig_w = 12 / bbox_aspect\n\n# create the figure and axis\nfig, ax = plt.subplots(figsize = (fig_w, fig_h))\nax.set_xlim(W, E)\nax.set_ylim(S, N)\nax.set_aspect(\"equal\")\n\nlines = []\nfor u, v, data in G_time.edges.keys():\n    lines.append([(G_time.nodes[u][\"x\"], G_time.nodes[u][\"y\"]),\n                  (G_time.nodes[v][\"x\"], G_time.nodes[v][\"y\"])])\n\nfrom matplotlib.collections import LineCollection\nax.add_collection(LineCollection(lines, colors = \"k\", linewidth = .5))\nplt.axis(\"off\")\n\n\n(-24.923310674353207,\n 27.844793379718062,\n -19.572596660049093,\n 21.215954647646313)"
  },
  {
    "objectID": "chapters/chap6/index.html",
    "href": "chapters/chap6/index.html",
    "title": "Chapter 6",
    "section": "",
    "text": "In this chapter the focus is squarely on networks (which mathematicians insist of calling graphs) and their potential for more relational understandings of space in giscience. As much of the code associated with the figures in this chapter shows, handling such structure elegantly is not something existing geospatial tools do well.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinks for Chapter 6\n\n\n\nlinks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigures 6.5 and 6.6: Reduced world city network viewed various ways\n\n\n\nfigures\n\n\ncode\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.10: The small world rewiring process\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.11: The small world rewiring process in two dimensions\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.12: A simple graph drawn nine different ways\n\n\n\nfigures\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.14: Relative time map of the Santa Barbara street network\n\n\n\nfigures\n\n\ncode\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap6/links-6.html",
    "href": "chapters/chap6/links-6.html",
    "title": "Links for Chapter 6",
    "section": "",
    "text": "The number of possible shortest paths, i.e., pairs of vertices, choosable from a graph of any given size is given by the numbers in integer sequence A000522.\n\n\n\nThe World City Network basic data set is available at the Globalisation and World Cities Research Network website. These data are used in figures 6.5, 6.6, and 6.13.\n\n\n\nSee Footnote 6 above.\n\n\n\nSee Footnote 6 above.\n\n\n\nStirling numbers of the 2nd kind are in integer sequence A008277. You can obtain values of these numbers at this web page.\n\n\n\nThe trade data used in this Figure and in Figure 6.9 are version 3 of the trade data currently available from the Correlates of War website.\n\n\n\nSee Figure 6.7 above.\n\n\n\nSee Footnote 6 above.\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap6/links-6.html#links",
    "href": "chapters/chap6/links-6.html#links",
    "title": "Links for Chapter 6",
    "section": "",
    "text": "The number of possible shortest paths, i.e., pairs of vertices, choosable from a graph of any given size is given by the numbers in integer sequence A000522.\n\n\n\nThe World City Network basic data set is available at the Globalisation and World Cities Research Network website. These data are used in figures 6.5, 6.6, and 6.13.\n\n\n\nSee Footnote 6 above.\n\n\n\nSee Footnote 6 above.\n\n\n\nStirling numbers of the 2nd kind are in integer sequence A008277. You can obtain values of these numbers at this web page.\n\n\n\nThe trade data used in this Figure and in Figure 6.9 are version 3 of the trade data currently available from the Correlates of War website.\n\n\n\nSee Figure 6.7 above.\n\n\n\nSee Footnote 6 above."
  },
  {
    "objectID": "chapters/chap6/fig6-10-small-world-1d.html",
    "href": "chapters/chap6/fig6-10-small-world-1d.html",
    "title": "Figure 6.10: The small world rewiring process",
    "section": "",
    "text": "The figure in the book shows only three rewiring steps for the sake of space. Here we show 11 with a probability of rewiring at each step of 0.05.\n\n\nCode\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tmap)\nlibrary(igraph)\n\nplot_graph &lt;- function(G, main='', vertex.color='black') {\n  plot(G, main = main,\n       layout = layout.circle(G), \n       vertex.label = NA, vertex.color = vertex.color, vertex.size = 5, \n       vertex.shape = 'circle', vertex.lwd = 0, \n       edge.color = 'black', edge.width = 0.5)\n}\n\npar(mar = rep(1, 4))\nlayout(matrix(1:12, nrow = 3, byrow = TRUE))\n\nthe_graph &lt;- make_lattice(50, dim = 1, circular = TRUE)\nplot_graph(the_graph)\n\nfor (i in 1:11) {\n  the_graph &lt;- rewire(the_graph, each_edge(0.05))\n  plot_graph(the_graph)\n}\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap6/fig6-11-small-world-2d.html",
    "href": "chapters/chap6/fig6-11-small-world-2d.html",
    "title": "Figure 6.11: The small world rewiring process in two dimensions",
    "section": "",
    "text": "Here the small world network phenomenon based on ‘rewiring’ is shown for a two-dimensional lattice. This particular network structure is less studied than might be expected, and can be considered a very simplified model for how even a small number of more rapid connections between places in a transportation network can dramatically alter its overall characteristics.\nCode\nlibrary(igraph)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(scales)\nlibrary(ggplot2)\nCode\nplot_graph &lt;- function(G, main = \"\", layout = layout.grid(G), \n                       vertex.color = \"black\") {\n  plot(G, main = main,\n       layout = layout, \n       vertex.label = NA, vertex.color = vertex.color, vertex.size = 5, \n       vertex.shape = \"circle\", vertex.lwd = 0, \n       edge.color = \"black\", edge.width = 0.5)\n}\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap6/fig6-11-small-world-2d.html#sample-rewired-2d-lattices",
    "href": "chapters/chap6/fig6-11-small-world-2d.html#sample-rewired-2d-lattices",
    "title": "Figure 6.11: The small world rewiring process in two dimensions",
    "section": "Sample rewired 2D lattices",
    "text": "Sample rewired 2D lattices\nIt’s somewhat useful to see what a range of rewired lattices look like. Here’s a bigger range than in the book, with the rewiring probability increasing roughly 3-fold each time.\n\n\nCode\npar(mar = rep(1, 4))\nlayout(matrix(1:6, nrow = 2, byrow = TRUE))\n\nbase_graph &lt;- make_lattice(length = 20, dim = 2, nei = 2)\n\nplot_graph(rewire(base_graph, each_edge(0.003)), main = \"p = 0.001\")\nplot_graph(rewire(base_graph, each_edge(0.009)), main = \"p = 0.005\")\nplot_graph(rewire(base_graph, each_edge(0.027)), main = \"p = 0.025\")\nplot_graph(rewire(base_graph, each_edge(0.083)), main = \"p = 0.125\")\nplot_graph(rewire(base_graph, each_edge(0.250)), main = \"p = 0.625\")\nplot_graph(rewire(base_graph, each_edge(0.750)), main = \"p = 0.625\")"
  },
  {
    "objectID": "chapters/chap6/fig6-11-small-world-2d.html#looking-at-a-wider-range-of-rewiring-outcomes",
    "href": "chapters/chap6/fig6-11-small-world-2d.html#looking-at-a-wider-range-of-rewiring-outcomes",
    "title": "Figure 6.11: The small world rewiring process in two dimensions",
    "section": "Looking at a wider range of rewiring outcomes",
    "text": "Looking at a wider range of rewiring outcomes\nBelow is code to make the other part of Figure 16.11, which shows how mean clustering coefficient and path lengths vary over a wide range of rewiring probablities. The range of probabilities shown here is different than in the published figure, with more of the samples in the middle range of the plot.\n\n\nCode\nprobs          &lt;- 10 ^ rnorm(1000, -3)\nprobs          &lt;- probs[which(between(probs, 0, 1))]\nkeepers        &lt;- c()\ncluster_coeffs &lt;- c()\nmean_path_lens &lt;- c()\n\nfor (i in seq_along(probs)) {\n  the_graph &lt;- rewire(base_graph, each_edge(probs[i]))\n  if (components(the_graph)$no == 1) {\n    cluster_coeffs &lt;- c(cluster_coeffs, \n                        transitivity(the_graph, type = \"average\"))\n    mean_path_lens &lt;- c(mean_path_lens, \n                        mean(distances(the_graph)))\n    keepers        &lt;- c(keepers, i)\n  }\n}\nprobs &lt;- probs[keepers]\n\ndf &lt;- data.frame(p   = probs, \n                 cc  = cluster_coeffs, \n                 mpl = mean_path_lens) %&gt;% \n  mutate(cc = rescale(cc, to = c(0, 1)), \n         mpl = rescale(mpl, to = c(0, 1))) %&gt;% \n  # remove first item, p=0 and not plottable\n  pivot_longer(-p) %&gt;%\n  rename(Metric = name)"
  },
  {
    "objectID": "chapters/chap6/fig6-11-small-world-2d.html#how-mean-path-length-and-clustering-coefficient-diverge",
    "href": "chapters/chap6/fig6-11-small-world-2d.html#how-mean-path-length-and-clustering-coefficient-diverge",
    "title": "Figure 6.11: The small world rewiring process in two dimensions",
    "section": "How mean path length and clustering coefficient diverge",
    "text": "How mean path length and clustering coefficient diverge\nThere is wide range of rewiring probabilities where ‘small world’ characteristic of surprising short mean path lengths in the presence of strong local clustering is evident (note the log-scale on the horizontal axis).\n\n\nCode\nggplot(df, aes(x = p, y = value, colour = Metric)) + \n  geom_point(cex = .8, alpha = 0.5) + \n  scale_x_log10() +\n  scale_colour_brewer(palette = \"Dark2\", \n                      labels = c(\"cluster_coeffs coeff.\", \"Mean path length\")) +\n  xlab(\"Probability of rewiring\") +\n  ylab(\"Value relative to base lattice\")\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "chapters/chap6/fig6-05-6-06-world-cities-network.html",
    "href": "chapters/chap6/fig6-05-6-06-world-cities-network.html",
    "title": "Figures 6.5 and 6.6: Reduced world city network viewed various ways",
    "section": "",
    "text": "This page includes python code derived from the code that was used to generate these figures. Again, you will see just how troublesome the limitations of existing platforms in handling projections intelligently can be. Some of the code is a bit overwhelming, so I’ve hidden most of it by default, but you can see it by clicking ► Code to view the code blocks.\nCode\nimport math\nimport pandas\nimport numpy\nimport networkx\nimport geopandas\nfrom shapely.geometry import LineString\nfrom shapely.geometry import MultiLineString\nfrom shapely.geometry import Point\nfrom shapely.geometry import MultiPoint\nfrom shapely.geometry import Polygon\n\n%matplotlib inline \nimport matplotlib.pyplot as plt\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap6/fig6-05-6-06-world-cities-network.html#the-base-data",
    "href": "chapters/chap6/fig6-05-6-06-world-cities-network.html#the-base-data",
    "title": "Figures 6.5 and 6.6: Reduced world city network viewed various ways",
    "section": "The base data",
    "text": "The base data\nThis is dataset 11 from the site linked here and shows the numbers of offices of 100 major firms that exist in a collection of 315 cities. The network we build is based on shared offices of firms, i.e. if two cities both have offices of the same firm, then we consider them related. To avoid a very dense network, we require the presence of a firm in a city to have been rated at least 4 (on a 5 point scale) in the dataset.\nFirst we read the data and have a look at it.\n\n\nCode\nwcn = pandas.read_csv(\"da11-1.csv\", index_col = 0)\nwcn.head(5)\n\n\n\n\n\n\n\n\n\nErnst & Young\nArthur Andersen\nMSI\nIGAF\nAGN\nBDO\nGrant Thornton\nHorwath\nKPMG\nSummit & Baker\n...\nMercer\nBoston\nDeloitte\nBoozeA&M\nA.T. Kearney\nMcKinsey\nBain\nCompass\nAndersen Consulting\nGemini\n\n\nname\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nABERDEEN\n2\n0\n0\n0\n0\n0\n0\n2\n2\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nABIJAN\n3\n0\n0\n0\n0\n0\n0\n0\n2\n0\n...\n0\n0\n2\n0\n0\n0\n0\n0\n0\n0\n\n\nABU DHABI\n2\n2\n0\n0\n2\n0\n0\n2\n2\n0\n...\n0\n0\n2\n2\n0\n0\n0\n0\n2\n0\n\n\nACCRA\n0\n0\n0\n0\n0\n0\n2\n0\n2\n0\n...\n0\n0\n2\n0\n0\n0\n0\n0\n0\n0\n\n\nADDIS ABABA\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n5 rows × 100 columns\n\n\n\n\nMaking the data into a network\nThe two functions in the code block below enable us to apply the ‘minimum score 4’ filter to the raw data, and then using matrix multiplication to convert the table into the adjacency matrix of a graph. This is based on the idea that an incidence matrix, \\(\\mathbf{B}\\), which the table is, can be multiplied by its transpose to yield an adjacency matrix, \\(\\mathbf{A}\\):\n\\[\\mathbf{A}=\\mathbf{B}\\mathbf{B}^{\\mathrm{T}}\\]\n\n\nCode\ndef cut_table_at(table: pandas.DataFrame, x: int) -&gt; pandas.DataFrame:\n    tbl = table.copy()\n    tbl[tbl[:] &lt; x] = 0  # remove cases &lt; x\n    tbl[tbl[:] &gt; 0] = 1  # set all remaining to 1\n    return tbl[list(tbl.sum(axis = 1) &gt; 0)]  # remove rows with no non-0 values\n\ndef make_network_from_incidence_table(tbl: pandas.DataFrame) -&gt; networkx.Graph:\n    incidence_matrix = numpy.array(tbl)\n    adj_matrix = incidence_matrix.dot(incidence_matrix.transpose())\n    numpy.fill_diagonal(adj_matrix, 0)\n    G = networkx.Graph(adj_matrix)\n    return networkx.relabel_nodes(G, dict(zip(G.nodes(), list(tbl.index))))"
  },
  {
    "objectID": "chapters/chap6/fig6-05-6-06-world-cities-network.html#the-geography",
    "href": "chapters/chap6/fig6-05-6-06-world-cities-network.html#the-geography",
    "title": "Figures 6.5 and 6.6: Reduced world city network viewed various ways",
    "section": "The geography",
    "text": "The geography\nBelow, we use the previous functions to form the graph, and then add longitude-latitude coordinates for each city to the nodes.\n\n\nCode\nGnx = make_network_from_incidence_table(cut_table_at(wcn, 4))\n\nwcn_ll = pandas.read_csv(\"wcn-cities-ll.csv\", index_col=0)\n\nfor name in Gnx.nodes():\n    lon = wcn_ll.loc[name][\"LONGITUDE\"]\n    lat = wcn_ll.loc[name][\"LATITUDE\"]\n    Gnx.nodes[name][\"lat\"] = lat\n    Gnx.nodes[name][\"lon\"] = lon\n\n\n\nA bad map\nAt this point, we can make up a naïve map (i.e. Figure 6.5a), simply connecting the end point coordinates of each edge in the graph with straight lines.\n\n\nCode\ncity_to_city = []\nfor e in Gnx.edges():\n    p1 = Point(Gnx.nodes[e[0]][\"lon\"], Gnx.nodes[e[0]][\"lat\"])\n    p2 = Point(Gnx.nodes[e[1]][\"lon\"], Gnx.nodes[e[1]][\"lat\"])\n    city_to_city.append(LineString([p1, p2]))\n\n# make up the naive links linestring dataset\ncity_to_city_gdf = geopandas.GeoDataFrame(\n  geometry = geopandas.GeoSeries(city_to_city))\ncity_to_city_gdf.crs = \"+proj=longlat\"\n\nmoll = \"+proj=moll\"\n# make up a 'globe' polygon for the background to the world maps\nglobe = Polygon(\n  [Point(-180, y) for y in [_ / 10 for _ in range(-900, 901)]] + \\\n  [Point( 180, y) for y in [_ / 10 for _ in range(900, -901, -1)]])\nglobe_gdf = geopandas.GeoDataFrame(geometry = geopandas.GeoSeries([globe]))\nglobe_gdf.crs = \"+proj=longlat\"\n\n# get countries data\ncountries = geopandas.read_file(\"ne-world.gpkg\")\n\n# and make up a map\nax = globe_gdf.to_crs(moll).plot(fc = \"#dddddd\")\ncountries.to_crs(moll).plot(ax = ax, fc = \"w\", linewidth = 0)\ncity_to_city_gdf.to_crs(moll).plot(ax = ax, color = \"k\", \n                                   alpha = 0.5, linewidth = 0.25)\nplt.axis(\"off\")\n\n\n(-19844105.265762024,\n 19844105.265762024,\n -9922052.632687533,\n 9922052.632687533)\n\n\n\n\n\n\n\nThe world is not flat\nThat map is not very useful, although avoiding making this kind of nonsense map is surprisingly difficult—another consequence of the limitations of how projections are handled in contemporary platforms. Things get complicated though… you have been warned…\nSo, we need several functions. First, the great circle distance beween two longitude-latitude points.\n\n\nCode\n# Uses the Haversine formulae, see\n# https://en.wikipedia.org/wiki/Haversine_formula\ndef get_great_circle_distance(p1: Point, p2: Point,\n                              R: float = 6378.137) -&gt; float:\n    lon0 = math.radians(p1.x)\n    lat0 = math.radians(p1.y)\n    lon1 = math.radians(p2.x)\n    lat1 = math.radians(p2.y)\n    dlon = lon1 - lon0\n    dlat = lat1 - lat0\n    a = math.sin(dlat / 2) * math.sin(dlat / 2) + \\\n        math.cos(lat0) * math.cos(lat1) * \\\n        math.sin(dlon / 2) * math.sin(dlon / 2)\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    return (R * c)\n\n\nNext, a function to return a great circle line (geodesic) between two points.\n\n\nCode\ndef interpolate_between(z1: float, z2: float, steps: int) -&gt; list[float]:\n    fractions = [(1 + x) / steps for x in range(steps - 1)]\n    return [z1] + [(z2 - z1) * f for f in fractions] + [z2]\n\ndef get_geodesic(p1: Point, p2: Point, step_length: int = 10) -&gt; LineString:\n    dist = get_great_circle_distance(p1, p2)\n    # determine number of steps\n    n_steps = math.ceil(dist / step_length) \n    # reproject in a space where great circles are straight lines\n    gdf = geopandas.GeoDataFrame(geometry = geopandas.GeoSeries([p1, p2]))\n    gdf.crs = \"+proj=longlat\"\n    gdf = gdf.to_crs(f\"+proj=aeqd +lon_0={p1.x} +lat_0={p1.y}\")\n    np1x, np1y = gdf.geometry[0].x, gdf.geometry[0].y\n    np2x, np2y = gdf.geometry[1].x, gdf.geometry[1].y\n    xs = interpolate_between(np1x, np2x, n_steps)\n    ys = interpolate_between(np1y, np2y, n_steps)\n    ngdf = geopandas.GeoDataFrame(geometry = geopandas.GeoSeries(\n        Point(x, y) for x, y in zip(xs, ys)))\n    ngdf.crs = f\"+proj=aeqd +lon_0={p1.x} +lat_0={p1.y}\"\n    points = list(ngdf.to_crs(\"+proj=longlat\").geometry)\n    return LineString((p.x, p.y) for p in points) \n\n\nNext, a function that takes geodesic and breaks itat any point where there is large apparent jump between consecutive points. Here we use the naïve distance measurement based on the coordinates. This will mean the line is broken at the antimeridian.\n\n\nCode\ndef split_at_antimeridian(geodesic: LineString) -&gt; \\\n        MultiLineString|MultiPoint|LineString:\n    points = geodesic.coords\n    # make into a series of LineStrings\n    segments = [LineString([p1, p2]) \n                   for p1, p2 in zip(points[:-1], points[1:])]\n    lengths = [ls.length for ls in segments]\n    intersections = [l &gt; 1 for l in lengths]\n    if True in intersections:\n        idx = intersections.index(True)\n        coords1 = points[:idx]\n        coords2 = points[idx+1:]\n        if len(coords1) &gt; 1 and len(coords2) &gt; 1:\n            return MultiLineString([coords1, coords2])\n        elif len(coords1) == 1 and len(coords2) == 1:\n            return MultiPoint(points)\n        else:\n            if len(coords1) &gt; len(coords2):\n                return LineString(coords1)\n            else:\n                return LineString(coords2)\n    else:\n        return LineString(points)\n\n\n\n\nMake geodesic datasets between the cities\n\n\nCode\ngeodesics = [] # list of LineStrings along the geodesic\ncut_geodesics = [] # list of the geodesics cut at the dateline\n\n# iterate over the edges\nfor e in Gnx.edges():\n  p1 = Point(Gnx.nodes[e[0]][\"lon\"], Gnx.nodes[e[0]][\"lat\"])\n  p2 = Point(Gnx.nodes[e[1]][\"lon\"], Gnx.nodes[e[1]][\"lat\"])\n  g = get_geodesic(p1, p2)\n  geodesics.append(g)\n  cut_geodesics.append(split_at_antimeridian(g))\n\ngeodesics_gdf = geopandas.GeoDataFrame(\n  geometry = geopandas.GeoSeries(geodesics))\ngeodesics_gdf.crs = \"+proj=longlat\"\n\ngeodesics_cut_gdf = geopandas.GeoDataFrame(\n  geometry = geopandas.GeoSeries(cut_geodesics))\ngeodesics_cut_gdf.crs = \"+proj=longlat\""
  },
  {
    "objectID": "chapters/chap6/fig6-05-6-06-world-cities-network.html#mollweide-fail-maps",
    "href": "chapters/chap6/fig6-05-6-06-world-cities-network.html#mollweide-fail-maps",
    "title": "Figures 6.5 and 6.6: Reduced world city network viewed various ways",
    "section": "Mollweide fail maps",
    "text": "Mollweide fail maps\nMore maps that don’t quite work. The first of these doesn’t break the great circle links at the anti-meridian (dateline) so we get ‘parallels’ from one side of the map to the other when one crosses the anti-meridian. The second\n\n\nCode\nax = globe_gdf.to_crs(moll).plot(fc = \"#dddddd\")\ncountries.to_crs(moll).plot(ax = ax, fc = \"w\", linewidth = 0)\ngeodesics_gdf.to_crs(moll).plot(ax = ax, color = \"k\", \n                                alpha = 0.5, linewidth = 0.25)\nplt.axis(\"off\")\n\nax = globe_gdf.to_crs(moll).plot(fc = \"#dddddd\")\ncountries.to_crs(moll).plot(ax = ax, fc = \"w\", linewidth = 0)\ngeodesics_cut_gdf.to_crs(moll).plot(ax = ax, color = \"k\", \n                                    alpha = 0.5, linewidth = 0.25)\nplt.axis(\"off\")\n\n\n(-19844105.265762024,\n 19844105.265762024,\n -9922052.632687533,\n 9922052.632687533)"
  },
  {
    "objectID": "chapters/chap6/fig6-05-6-06-world-cities-network.html#orthographic-not-so-fail-maps",
    "href": "chapters/chap6/fig6-05-6-06-world-cities-network.html#orthographic-not-so-fail-maps",
    "title": "Figures 6.5 and 6.6: Reduced world city network viewed various ways",
    "section": "Orthographic not so fail maps",
    "text": "Orthographic not so fail maps\n\n\nCode\natlantic = \"+proj=ortho +lon_0=0 +lat_0=0\"\npacific = \"+proj=ortho +lon_0=180 +lat_0=0\"\nhalf_globe = globe_gdf.copy()\nhalf_globe.geometry = half_globe.geometry.scale(xfact = 0.5)\n\ncountries_a = geopandas.read_file(\"atlantic.gpkg\").to_crs(atlantic)\ncountries_p = geopandas.read_file(\"pacific.gpkg\").to_crs(pacific)\n\nax = half_globe.to_crs(atlantic).plot(fc = \"#dddddd\")\ncountries_a.to_crs(atlantic).plot(ax = ax, fc = \"w\", linewidth = 0)\ngeodesics_cut_gdf.to_crs(atlantic).plot(ax = ax, color = \"k\",\n                                        alpha = 0.5, linewidth = 0.25)\nplt.axis(\"off\")\n\nax = half_globe.to_crs(pacific).plot(fc = \"#dddddd\")\ncountries_p.to_crs(pacific).plot(ax = ax, fc = \"w\", linewidth = 0)\ngeodesics_cut_gdf.to_crs(pacific).plot(ax = ax, color = \"k\", \n                                       alpha = 0.5, linewidth = 0.25)\nplt.axis(\"off\")\n\n\n(-7015950.7, 7015950.7, -6992427.545669697, 6992427.545669697)"
  },
  {
    "objectID": "chapters/chap6/fig6-12-graph-drawings.html",
    "href": "chapters/chap6/fig6-12-graph-drawings.html",
    "title": "Figure 6.12: A simple graph drawn nine different ways",
    "section": "",
    "text": "The main difference here is that the output is in colour, which might make it easier to see what’s going on.\n\n\nCode\nlibrary(igraph)\nlibrary(dplyr)\nlibrary(RColorBrewer)\nlibrary(ggplot2)\n\n\n\n\nCode\nplot_graph &lt;- function(G, main = \"\", layout = layout.grid(G), \n                       vertex.color = \"black\") {\n  plot(G, main = main,\n       layout = layout, \n       vertex.label = NA, vertex.color = vertex.color, vertex.size = 5, \n       vertex.shape = \"circle\", vertex.frame.width = 0, \n       edge.color = \"black\", edge.width = 0.5)\n}\n\n\n\n\nCode\nthe_graph &lt;- make_lattice(length = 20, dim = 2, nei = 1)\nthe_graph &lt;- rewire(the_graph, each_edge(1/400))\nvertex_attr(the_graph, 'centrality') &lt;- centralization.closeness(the_graph)$res\n\n# make a bespoke colour for each vertex based on centrality\nbase_pal &lt;- brewer.pal(11, 'RdYlBu')\npal = colorRampPalette(base_pal)\ngraphCol = pal(500)[as.numeric(cut(V(the_graph)$centrality, breaks = 500))]\n\npar(mar = rep(1, 4))\nlayout(matrix(1:9, 3, 3, byrow = TRUE))\n\nplot_graph(the_graph, layout = layout_randomly(the_graph), vertex.color = graphCol)\nplot_graph(the_graph, layout = layout.circle(the_graph), vertex.color = graphCol)\nplot_graph(the_graph, layout = layout_with_mds(the_graph), vertex.color = graphCol)\nplot_graph(the_graph, layout = layout_as_tree(the_graph), vertex.color = graphCol)\nplot_graph(the_graph, vertex.color = graphCol)\nplot_graph(the_graph, layout = layout_as_tree(the_graph, circular = TRUE), vertex.color = graphCol)\nplot_graph(the_graph, layout = layout.kamada.kawai(the_graph), vertex.color = graphCol)\nplot_graph(the_graph, layout = layout.drl(the_graph), vertex.color = graphCol)\nplot_graph(the_graph, layout = layout.fruchterman.reingold(the_graph), vertex.color = graphCol)\n\n\n\n\n\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE.\n\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap1/index.html",
    "href": "chapters/chap1/index.html",
    "title": "Chapter 1",
    "section": "",
    "text": "Chapter 1 sets out the overall plan of the book, putting in the context of my own history with doing giscience in relation (often distant) with the rest of geography.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinks for Chapter 1\n\n\n\nlinks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap1/links-1.html",
    "href": "chapters/chap1/links-1.html",
    "title": "Links for Chapter 1",
    "section": "",
    "text": "Footnote 6\nYou’ll find my PhD thesis here: Graph-based Cellular Automaton Models of Urban Spatial Processes. Chapter 2 is the slightly embarrassing take on space, mentioned in the note.\n\n\nFootnote 8\nSlides from the course I developed at Berkeley and taught from 2014 to 2018 Geog 80 Digital Worlds: An Introduction to Geospatial Technologies\n\n\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap8/links-8.html",
    "href": "chapters/chap8/links-8.html",
    "title": "Links for Chapter 8",
    "section": "",
    "text": "The XKCD comic marking the passing of John Conway is at xkcd.com.\n\n\n\nCosma Shalizi’s notes on D’Arcy Thompson are at http://bactra.org/notebooks/darcy-thompson.html (yes http, not https). Attention preservation notice: Cosma Shalizi’s website is a rabbithole!\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "chapters/chap8/links-8.html#links",
    "href": "chapters/chap8/links-8.html#links",
    "title": "Links for Chapter 8",
    "section": "",
    "text": "The XKCD comic marking the passing of John Conway is at xkcd.com.\n\n\n\nCosma Shalizi’s notes on D’Arcy Thompson are at http://bactra.org/notebooks/darcy-thompson.html (yes http, not https). Attention preservation notice: Cosma Shalizi’s website is a rabbithole!"
  },
  {
    "objectID": "chapters/chap8/index.html",
    "href": "chapters/chap8/index.html",
    "title": "Chapter 8",
    "section": "",
    "text": "I’ve been interested in pattern and process for a long time. In this book, I approach them the other way around, starting with process, recognising that if the world really is anything, it’s processes all the way down, not things at all. This involves engaging some process philosophy, which is a wild ride! Recognising pattern can offer us a way into that world.\nComplexity science may be one way for giscience to grapple with these ontological challenges, and it (i.e. complexity science) is where I started my geographical journey, and what drew me into the PhD program at UCL’s CASA to work with Mike Batty. So, while this is the last major chapter in the book, it’s likely the one where the themes will be most familiar to anyone who has read any of my earlier work!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinks for Chapter 8\n\n\n\nlinks\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computing Geographically",
    "section": "",
    "text": "This website provides a collection of resources for the book Computing Geographically: Bridging Giscience and Geography (Guilford Press, New York).\nIncluded are:\n\nCurrent links for internet sources referenced in the text\nCode samples to create the base graphics for some of the figures\nBackground information on other figures\n\nAccess them either from the drop-down menu by chapter, or from this listing page.\n\n\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "other-stuff/index.html",
    "href": "other-stuff/index.html",
    "title": "Other stuff",
    "section": "",
    "text": "For now, this is just one page about how I made the cover art. In time I might expand it to cover other aspects of the book, why I wrote it, lost chapters/threads that didn’t make it, a picture of Rosa the cat, ‘how I wrote a book and still lost my job’, and so on.\nBut for now, here’s how I made the cover art.\n© 2023 David O’Sullivan"
  },
  {
    "objectID": "other-stuff/index.html#a-flocking-model",
    "href": "other-stuff/index.html#a-flocking-model",
    "title": "Other stuff",
    "section": "A flocking model",
    "text": "A flocking model\nThe starting point was a flocking model, which is discussed in Chapter 8 of the book, in §Agent-Based Models, but also makes an appearance in Figure 7.7. This model was previously made for my earlier book Spatial Simulation written with George Perry, which you can find all about here. Specifically this NetLogo model appears in the model zoo, as an implementation of ideas in these papers\n\nCzirók A and T Vicsek. 2000. Collective behavior of interacting self-propelled particles. Physica A: Statistical Mechanics and its Applications 281 17–29.\n\n\nGrégoire G, H Chaté and Y Tu. 2003. Moving and staying together without a leader. Physica D: Nonlinear Phenomena 181 157–70.\n\n\nVicsek T, A Czirók, E Ben-Jacob, I Cohen and O Sochet. 1995. Novel type of phase transition in a system of self-driven particles. Physical Review Letters 75 1226–29.\n\nYou can play with a—rather slow, because the web version is slow—version of that model here. If you download and run it locally, you’ll find some commented out code at the end that implements a save-history procedure that means you can run the model for a bit then get a CSV file with who, x, y, and t output for the flockers, which is the basis for the cover art. who is NetLogo’s endearing default variable name that we would more often think of as ‘ID’ or similar. It’s because the moving things in NetLogo are turtles, not mere simple locations. This puts me in mind of Gillian Rose and Torsten Hägerstrand’s thoughts on the living bodies at the tips of space-time paths, as discussed in §Limits to Time Geography in Chapter 7."
  },
  {
    "objectID": "other-stuff/index.html#the-space-time-traces",
    "href": "other-stuff/index.html#the-space-time-traces",
    "title": "Other stuff",
    "section": "The space-time traces",
    "text": "The space-time traces\nSo, after importing some packages, read in one of those output files. There’s an example here, should you wish to make your own alternative cover.\n\n\nCode\nlibrary(sf)\nlibrary(tmap)\nlibrary(dplyr)\nlibrary(units)\n\nxy &lt;- read.table(\"traces.csv\", sep = \" \", header = TRUE)\n\n\nWe don’t need all the time steps in that file, so cut it down a bit and convert into a simple features dataset. You’ll note that even though these are not real world data (this is a book cover after all) I have to assign a projection, so that some of the later steps in the process will cooperate. The curse of geodetic accuracy strikes again!\n\n\nCode\nsteps &lt;- seq(1, 50, 1)\n\nxy_sf &lt;- xy %&gt;%\n  mutate(x = x + 1.75e6, y = y + 5.5e6) %&gt;%\n  filter(t %in% steps) %&gt;%\n  st_as_sf(coords = c(\"x\", \"y\"), crs = 2193)\n\n\nBefore we go any further, we need a ‘frame’ for all the layers we’ll be using, so this is made from the extent of the included points, inset a little. Insetting avoids some otherwise strange edge effects.\n\n\nCode\nxy_inset &lt;- xy_sf %&gt;%\n  st_bbox() %&gt;%\n  st_as_sfc() %&gt;%\n  st_sf() %&gt;%\n  st_set_crs(2193) %&gt;%\n  st_buffer(-.5)\n\n\nThe underlying basis of the cover art is those traces, which we need to form into a lines dataset and clip to the frame.\n\n\nCode\nxy_path &lt;- xy_sf %&gt;%\n  group_by(who) %&gt;%\n  summarise(do_union = FALSE) %&gt;%\n  st_cast(\"LINESTRING\") %&gt;% \n  st_intersection(xy_inset)\n\n\nSo this is what we’ve got so far:\n\n\nCode\ntm_shape(xy_path) + \n  tm_lines(lwd = 0.5)"
  },
  {
    "objectID": "other-stuff/index.html#voronoi-polygons-of-the-trajectory-points",
    "href": "other-stuff/index.html#voronoi-polygons-of-the-trajectory-points",
    "title": "Other stuff",
    "section": "Voronoi polygons of the trajectory points",
    "text": "Voronoi polygons of the trajectory points\nProbably you can tell that some Voronoi magic was involved, specifically Voronoi polygons of the points along the trajectories, in a manner reminiscent of the Voronois along the road centre line in Figure 2.8.\n\n\nCode\nxy_vor &lt;- xy_sf %&gt;%\n  st_union() %&gt;%\n  st_voronoi() %&gt;%\n  st_cast() %&gt;%\n  st_as_sf(crs = st_crs(xy_sf)) %&gt;%\n  st_join(xy_sf) %&gt;%\n  st_intersection(xy_inset) %&gt;%\n  distinct(geometry)\n\n\nAnd here is what we have got so far:\n\n\nCode\ntm_shape(xy_vor) +\n  tm_borders(col = \"blue\", lwd = 0.35) +\n  tm_shape(xy_path) + \n  tm_lines(lwd = 0.5)\n\n\n\n\n\nwhich is already pretty interesting looking."
  },
  {
    "objectID": "other-stuff/index.html#overlapping-voronoi-polygons",
    "href": "other-stuff/index.html#overlapping-voronoi-polygons",
    "title": "Other stuff",
    "section": "Overlapping Voronoi polygons",
    "text": "Overlapping Voronoi polygons\nThe cover depends on overlapping the Voronoi polygons, which when coloured with some transparency gives the final effect. So some buffering (the original sin of GIS!) required. I decided after much experimentation to make the buffers larger for the bigger polygons.\n\n\nCode\nxy_vor_b &lt;- xy_vor %&gt;%\n  mutate(area = st_area(.), r = as_units(.25, \"m\") + sqrt(area / pi)) %&gt;%\n  st_buffer(.$r) %&gt;%\n  st_intersection(xy_inset)\n\n\nIn itself this is also interesting to look at:\n\n\nCode\ntm_shape(xy_vor_b) + \n  tm_borders(lwd = 0.15)"
  },
  {
    "objectID": "other-stuff/index.html#putting-it-all-together",
    "href": "other-stuff/index.html#putting-it-all-together",
    "title": "Other stuff",
    "section": "Putting it all together",
    "text": "Putting it all together\nArmed with those three layers, we can do all kinds of interesting compositions. It’s fun to play with the colour palettes, the transparency, the direction of the ramps, and any number of other things. Here’s what I wound up using:\n\n\nCode\ntm_shape(xy_vor_b)  +\n  tm_polygons(col = \"r\", alpha = 0.3, style = \"cont\", lwd = 0,\n              palette = \"-plasma\", legend.show = FALSE) +\n  tm_shape(xy_vor) +\n  tm_borders(col = \"white\", alpha = 0.35, lwd = 0.35) +\n  tm_shape(xy_path) +\n  tm_lines(col = \"white\", palette = \"Blues\", lwd = 1, alpha = 0.5) +\n  tm_layout(frame = FALSE, bg.color = \"white\")"
  },
  {
    "objectID": "other-stuff/index.html#other-computational-art-in-r",
    "href": "other-stuff/index.html#other-computational-art-in-r",
    "title": "Other stuff",
    "section": "Other computational art in R",
    "text": "Other computational art in R\nComputational ‘generative’ art is a lot of fun. I’d have to rewrite that NetLogo model in R to make this truly an example of generative art in R, but en route to this approach I found some interesting resources here, particularly\n\nhttps://nrennie.rbind.io/portfolio/rtistry/\nhttps://github.com/koenderks/aRtsy\n\nIn the end I preferred the greater control that my own ‘tool-chain’ gave me."
  },
  {
    "objectID": "other-stuff/index.html#the-idea-behind-the-cover",
    "href": "other-stuff/index.html#the-idea-behind-the-cover",
    "title": "Other stuff",
    "section": "The idea behind the cover",
    "text": "The idea behind the cover\nLoosely speaking the cover mirrors the sequence from ‘simple location’ to ‘world as relational process’ that the book recounts. A set of relationally interacting, moving, simple locations converge to become a society of actual occasions. If you have no idea what I’m on about, you’ll have to read the book…\nIn any case, I like how it looks, and so did the publisher!\n\n\nCode\n# License (MIT)\n#\n# Copyright (c) 2023 David O'Sullivan\n#\n# Permission is hereby granted, free of charge, to any person\n# obtaining a copy of this software and associated documentation\n# files (the \"Software\"), to deal in the Software without restriction,\n# including without limitation the rights to use, copy, modify, merge,\n# publish, distribute, sublicense, and/or sell copies of the Software,\n# and to  permit persons to whom the Software is furnished to do so,\n# subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included\n# in all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n# OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE."
  }
]